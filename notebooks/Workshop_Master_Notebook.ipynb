{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workshop_header"
      },
      "source": [
        "# üå°Ô∏è Climate Model Validation Workshop\n",
        "\n",
        "## Complete End-to-End Analysis\n",
        "**Study Area:** AMMAN ZARQA Basin, Jordan  \n",
        "**Models:** 6 RICCAR Climate Models (SSP4.5)  \n",
        "**Stations:** AL0019, AL0035, AL0059  \n",
        "**Period:** 1990-2014\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Workshop Overview\n",
        "\n",
        "### **Part 1: Station Data Extraction** üìç\n",
        "- Download climate model NetCDF files\n",
        "- Extract temperature data at station locations\n",
        "\n",
        "### **Part 2: Monthly Climatology** üìä\n",
        "- Convert daily data to monthly climatology\n",
        "- Calculate seasonal temperature patterns\n",
        "\n",
        "### **Part 3: Station Data Processing** üå°Ô∏è\n",
        "- Load observed temperature data\n",
        "- Process station climatology\n",
        "\n",
        "### **Part 4: Model Validation** üéì\n",
        "- Calculate 5 validation metrics (RMSE, R, NSE, PBIAS, MAE)\n",
        "- Compare models against observations\n",
        "- Rank model performance\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Learning Objectives\n",
        "- ‚úÖ Extract and process climate data using Python\n",
        "- ‚úÖ Calculate validation metrics and interpret results\n",
        "- ‚úÖ Create publication-quality visualizations\n",
        "- ‚úÖ Make informed decisions about model selection\n",
        "\n",
        "**Estimated Time: 45-60 minutes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "# ‚öôÔ∏è Setup: Install Packages and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "!pip install xarray netcdf4 requests tqdm seaborn -q\n",
        "print(\"‚úÖ Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"üìö Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_data"
      },
      "outputs": [],
      "source": [
        "def download_workshop_data():\n",
        "    \"\"\"Download all required files from GitHub repository\"\"\"\n",
        "    \n",
        "    print(\"üéØ DOWNLOADING WORKSHOP DATA\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    base_url = \"https://raw.githubusercontent.com/MoawiahHussien/climate-model-validation-workshop/main/\"\n",
        "    \n",
        "    os.makedirs(\"input_data/models_netcdf\", exist_ok=True)\n",
        "    os.makedirs(\"input_data/stations_data\", exist_ok=True)\n",
        "    \n",
        "    nc_files = [\n",
        "        \"arcgis_merged_Tmax_CMCC-CM2-SR5.nc\",\n",
        "        \"arcgis_merged_Tmax_CNRM-ESM2-1.nc\", \n",
        "        \"arcgis_merged_Tmax_EC-Earth3-Veg.nc\",\n",
        "        \"arcgis_merged_Tmax_IPSL-CM6A-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_MPI-ESM1-2-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_NorESM2-MM.nc\"\n",
        "    ]\n",
        "    \n",
        "    station_files = [\"AL0019.xlsx\", \"AL0035.xlsx\", \"AL0059.xlsx\"]\n",
        "    \n",
        "    print(\"üì• Downloading climate model files...\")\n",
        "    for nc_file in nc_files:\n",
        "        file_url = base_url + \"Input%20Files/Models.Nc.ArcGIS.Compatible/\" + nc_file\n",
        "        local_path = f\"input_data/models_netcdf/{nc_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"‚úÖ Using cached: {nc_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"üì• Downloading: {nc_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   ‚úÖ Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Failed: {e}\")\n",
        "    \n",
        "    print(\"\\nüì• Downloading station files...\")\n",
        "    for station_file in station_files:\n",
        "        file_url = base_url + \"Input%20Files/Stations.Daily/\" + station_file\n",
        "        local_path = f\"input_data/stations_data/{station_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"‚úÖ Using cached: {station_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"üì• Downloading: {station_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   ‚úÖ Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Failed: {e}\")\n",
        "    \n",
        "    print(f\"\\nüéâ Data download complete!\")\n",
        "\n",
        "download_workshop_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define_constants"
      },
      "outputs": [],
      "source": [
        "# Workshop configuration\n",
        "stations = {\n",
        "    'AL0019': {'lat': 31.95, 'lon': 35.93, 'name': 'Amman Airport'},\n",
        "    'AL0035': {'lat': 32.01, 'lon': 35.85, 'name': 'Zarqa Station'}, \n",
        "    'AL0059': {'lat': 31.97, 'lon': 36.12, 'name': 'Russeifa Station'}\n",
        "}\n",
        "\n",
        "model_files = {\n",
        "    'CMCC': 'arcgis_merged_Tmax_CMCC-CM2-SR5.nc',\n",
        "    'CNRM': 'arcgis_merged_Tmax_CNRM-ESM2-1.nc',\n",
        "    'EC-Earth3': 'arcgis_merged_Tmax_EC-Earth3-Veg.nc',\n",
        "    'IPSL': 'arcgis_merged_Tmax_IPSL-CM6A-LR.nc',\n",
        "    'MPI': 'arcgis_merged_Tmax_MPI-ESM1-2-LR.nc',\n",
        "    'NorESM2': 'arcgis_merged_Tmax_NorESM2-MM.nc'\n",
        "}\n",
        "\n",
        "model_colors = {\n",
        "    'CMCC': '#1f77b4', 'CNRM': '#ff7f0e', 'EC-Earth3': '#2ca02c',\n",
        "    'IPSL': '#d62728', 'MPI': '#9467bd', 'NorESM2': '#8c564b'\n",
        "}\n",
        "\n",
        "print(f\"üéØ WORKSHOP CONFIGURATION\")\n",
        "print(f\"üìç Target Stations: {len(stations)}\")\n",
        "print(f\"üå°Ô∏è Climate Models: {len(model_files)}\")\n",
        "for station_id, info in stations.items():\n",
        "    print(f\"  {station_id}: {info['name']} ({info['lat']:.2f}¬∞N, {info['lon']:.2f}¬∞E)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1_header"
      },
      "source": [
        "# üìç Part 1: Station Data Extraction from Climate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_station_data"
      },
      "outputs": [],
      "source": [
        "def extract_station_data():\n",
        "    \"\"\"Extract temperature data at station locations from all models\"\"\"\n",
        "    \n",
        "    print(f\"üìç EXTRACTING DATA AT STATION LOCATIONS\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    model_station_data = {}\n",
        "    extraction_log = []\n",
        "    \n",
        "    for model_name, filename in model_files.items():\n",
        "        print(f\"\\nüîÑ Processing: {model_name}\")\n",
        "        \n",
        "        file_path = f\"input_data/models_netcdf/{filename}\"\n",
        "        \n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"    ‚ùå File not found: {filename}\")\n",
        "            continue\n",
        "        \n",
        "        ds = xr.open_dataset(file_path)\n",
        "        model_station_data[model_name] = {}\n",
        "        \n",
        "        for station_id, station_info in stations.items():\n",
        "            station_data = ds.tasmaxAdjust.sel(\n",
        "                lat=station_info['lat'], \n",
        "                lon=station_info['lon'], \n",
        "                method='nearest'\n",
        "            )\n",
        "            \n",
        "            grid_lat = float(station_data.lat.values)\n",
        "            grid_lon = float(station_data.lon.values)\n",
        "            distance_km = np.sqrt((grid_lat - station_info['lat'])**2 + \n",
        "                                (grid_lon - station_info['lon'])**2) * 111\n",
        "            \n",
        "            model_station_data[model_name][station_id] = station_data.values\n",
        "            \n",
        "            extraction_log.append({\n",
        "                'Model': model_name,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': station_info['name'],\n",
        "                'Distance_km': round(distance_km, 2),\n",
        "                'Days_Extracted': len(station_data),\n",
        "                'Valid_Days': int(np.sum(~np.isnan(station_data.values)))\n",
        "            })\n",
        "            \n",
        "            print(f\"    ‚úÖ {station_id}: {len(station_data)} days, distance: {distance_km:.2f} km\")\n",
        "        \n",
        "        ds.close()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Part 1 Complete: {len(extraction_log)} extractions\")\n",
        "    return model_station_data, pd.DataFrame(extraction_log)\n",
        "\n",
        "extracted_data, extraction_summary = extract_station_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "part1_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 1 visualization\n",
        "summary_data = []\n",
        "for model_name in extracted_data.keys():\n",
        "    for station_id in extracted_data[model_name].keys():\n",
        "        temp_data = extracted_data[model_name][station_id]\n",
        "        summary_data.append({\n",
        "            'Model': model_name,\n",
        "            'Station': station_id,\n",
        "            'Station_Name': stations[station_id]['name'],\n",
        "            'Mean_Temp': round(np.nanmean(temp_data), 2)\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Distance to grid points\n",
        "ax1 = axes[0]\n",
        "extraction_summary.boxplot(column='Distance_km', by='Station', ax=ax1)\n",
        "ax1.set_title('Distance to Nearest Grid Point\\n(Spatial Resolution Check)', fontweight='bold')\n",
        "ax1.set_ylabel('Distance (km)')\n",
        "ax1.set_xlabel('Station ID')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Temperature by model\n",
        "ax2 = axes[1]\n",
        "models = list(model_colors.keys())\n",
        "model_temps = [summary_df[summary_df['Model'] == model]['Mean_Temp'].values for model in models]\n",
        "bp = ax2.boxplot(model_temps, labels=models, patch_artist=True, widths=0.6)\n",
        "for patch, model in zip(bp['boxes'], models):\n",
        "    patch.set_facecolor(model_colors[model])\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax2.set_title('Mean Temperature by Model\\n1990-2014 Daily Average', fontweight='bold')\n",
        "ax2.set_ylabel('Temperature (¬∞C)')\n",
        "ax2.set_xlabel('Climate Model')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "fig.suptitle('Part 1: Climate Model Data Extraction Results', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüéØ PART 1 SUMMARY\")\n",
        "print(f\"‚úÖ Models processed: {len(extracted_data)}\")\n",
        "print(f\"‚úÖ Stations extracted: {len(stations)}\")\n",
        "avg_distance = extraction_summary['Distance_km'].mean()\n",
        "print(f\"üìè Average grid distance: {avg_distance:.2f} km\")\n",
        "print(f\"\\n‚û°Ô∏è Ready for Part 2: Monthly Climatology Calculation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2_header"
      },
      "source": [
        "# üìä Part 2: Monthly Climatology Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "calculate_climatology"
      },
      "outputs": [],
      "source": [
        "def calculate_monthly_climatology_from_memory(extracted_data):\n",
        "    \"\"\"Calculate monthly climatology from extracted data in memory\"\"\"\n",
        "    \n",
        "    print(f\"üìä CALCULATING MONTHLY CLIMATOLOGY\")\n",
        "    print(\"-\" * 35)\n",
        "    \n",
        "    climatology_data = []\n",
        "    \n",
        "    for model_name in extracted_data.keys():\n",
        "        for station_id in extracted_data[model_name].keys():\n",
        "            \n",
        "            print(f\"  üîÑ Processing {model_name} - {station_id}\")\n",
        "            \n",
        "            temp_data = extracted_data[model_name][station_id]\n",
        "            time_index = pd.date_range('1990-01-01', periods=len(temp_data), freq='D')\n",
        "            \n",
        "            df = pd.DataFrame({\n",
        "                'Date': time_index,\n",
        "                'Temperature_C': temp_data\n",
        "            })\n",
        "            \n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            \n",
        "            monthly_clim = df.groupby('Month')['Temperature_C'].agg([\n",
        "                ('Mean_Temp', 'mean'),\n",
        "                ('Min_Temp', 'min'),\n",
        "                ('Max_Temp', 'max'),\n",
        "                ('Std_Temp', 'std')\n",
        "            ]).round(2)\n",
        "            \n",
        "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "            monthly_clim['Month_Name'] = month_names\n",
        "            monthly_clim['Model'] = model_name\n",
        "            monthly_clim['Station'] = station_id\n",
        "            monthly_clim['Station_Name'] = stations[station_id]['name']\n",
        "            monthly_clim = monthly_clim.reset_index()\n",
        "            \n",
        "            climatology_data.append(monthly_clim)\n",
        "    \n",
        "    all_climatology = pd.concat(climatology_data, ignore_index=True)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Part 2 Complete: Monthly climatology for {len(climatology_data)} model-station combinations\")\n",
        "    return all_climatology\n",
        "\n",
        "model_climatology = calculate_monthly_climatology_from_memory(extracted_data)\n",
        "\n",
        "if model_climatology is not None:\n",
        "    print(f\"\\nüìä Climatology Summary:\")\n",
        "    print(f\"  Total records: {len(model_climatology)}\")\n",
        "    print(f\"  Models: {model_climatology['Model'].nunique()}\")\n",
        "    print(f\"  Stations: {model_climatology['Station'].nunique()}\")\n",
        "    print(f\"  Temperature range: {model_climatology['Mean_Temp'].min():.1f}¬∞C to {model_climatology['Mean_Temp'].max():.1f}¬∞C\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "climatology_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 2 visualization\n",
        "if model_climatology is not None:\n",
        "    \n",
        "    print(f\"üìà CREATING CLIMATOLOGY VISUALIZATION\")\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    stations_order = ['AL0019', 'AL0035', 'AL0059']\n",
        "    \n",
        "    for i, station_id in enumerate(stations_order):\n",
        "        ax = axes[i]\n",
        "        \n",
        "        for model in model_climatology['Model'].unique():\n",
        "            data = model_climatology[(model_climatology['Model'] == model) & \n",
        "                                    (model_climatology['Station'] == station_id)]\n",
        "            \n",
        "            if not data.empty:\n",
        "                months = data['Month'].values\n",
        "                temps = data['Mean_Temp'].values\n",
        "                \n",
        "                ax.plot(months, temps, 'o-', color=model_colors[model], \n",
        "                       label=model, linewidth=2, markersize=6, alpha=0.8)\n",
        "        \n",
        "        ax.set_title(f'{station_id}\\n({stations[station_id][\"name\"]})', fontweight='bold')\n",
        "        ax.set_xlabel('Month')\n",
        "        ax.set_ylabel('Temperature (¬∞C)')\n",
        "        ax.set_xticks(range(1, 13))\n",
        "        ax.set_xticklabels(['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D'])\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        if i == 2:\n",
        "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "    \n",
        "    fig.suptitle('Part 2: Monthly Temperature Climatology by Station\\n1990-2014 Average (All Models)', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(right=0.85)\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nüéØ PART 2 SUMMARY\")\n",
        "    print(f\"‚úÖ Monthly climatology calculated for {len(model_climatology['Model'].unique())} models\")\n",
        "    print(f\"‚úÖ {len(model_climatology['Station'].unique())} stations processed\")\n",
        "    print(f\"‚úÖ Temperature range: {model_climatology['Mean_Temp'].min():.1f}¬∞C to {model_climatology['Mean_Temp'].max():.1f}¬∞C\")\n",
        "    print(f\"\\n‚û°Ô∏è Ready for Part 3: Station Data Processing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3_header"
      },
      "source": [
        "# üå°Ô∏è Part 3: Station Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process_station_data"
      },
      "outputs": [],
      "source": [
        "def process_station_data():\n",
        "    \"\"\"Process observed station data for validation\"\"\"\n",
        "    \n",
        "    print(f\"üå°Ô∏è PROCESSING STATION DATA\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    station_climatology = []\n",
        "    target_stations = ['AL0019', 'AL0035', 'AL0059']\n",
        "    \n",
        "    for station_id in target_stations:\n",
        "        station_file = f\"input_data/stations_data/{station_id}.xlsx\"\n",
        "        \n",
        "        if not os.path.exists(station_file):\n",
        "            print(f\"‚ùå Station file not found: {station_id}.xlsx\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"üîÑ Processing station: {station_id}\")\n",
        "        \n",
        "        try:\n",
        "            df = pd.read_excel(station_file)\n",
        "            \n",
        "            if 'Date' not in df.columns or 'Corrected Tmax' not in df.columns:\n",
        "                print(f\"‚ùå Missing required columns in {station_id}\")\n",
        "                continue\n",
        "            \n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df = df[(df['Date'].dt.year >= 1990) & (df['Date'].dt.year <= 2014)]\n",
        "            df['Temperature'] = pd.to_numeric(df['Corrected Tmax'], errors='coerce')\n",
        "            df = df[(df['Temperature'] >= -20) & (df['Temperature'] <= 60)]\n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            \n",
        "            monthly_clim = df.groupby('Month')['Temperature'].agg([\n",
        "                ('Mean_Temp', 'mean'),\n",
        "                ('Min_Temp', 'min'),\n",
        "                ('Max_Temp', 'max'),\n",
        "                ('Std_Temp', 'std'),\n",
        "                ('Count', 'count')\n",
        "            ]).round(2)\n",
        "            \n",
        "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "            monthly_clim['Month_Name'] = month_names\n",
        "            monthly_clim['Station'] = station_id\n",
        "            monthly_clim['Station_Name'] = stations[station_id]['name']\n",
        "            monthly_clim = monthly_clim.reset_index()\n",
        "            \n",
        "            station_climatology.append(monthly_clim)\n",
        "            \n",
        "            valid_days = df['Temperature'].notna().sum()\n",
        "            total_days = len(df)\n",
        "            completeness = (valid_days / total_days) * 100\n",
        "            \n",
        "            print(f\"  ‚úÖ {station_id}: {completeness:.1f}% data completeness\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Error processing {station_id}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if station_climatology:\n",
        "        combined_station_clim = pd.concat(station_climatology, ignore_index=True)\n",
        "        print(f\"\\n‚úÖ Part 3 Complete: Station climatology for {len(station_climatology)} stations\")\n",
        "        return combined_station_clim\n",
        "    else:\n",
        "        print(\"‚ùå No station data processed\")\n",
        "        return None\n",
        "\n",
        "station_climatology = process_station_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "station_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 3 visualization\n",
        "if station_climatology is not None:\n",
        "    \n",
        "    print(\"üìä CREATING STATION VISUALIZATION\")\n",
        "    \n",
        "    station_colors = {'AL0019': '#1f77b4', 'AL0035': '#ff7f0e', 'AL0059': '#2ca02c'}\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # Monthly climatology\n",
        "    ax1 = axes[0]\n",
        "    for station_id in ['AL0019', 'AL0035', 'AL0059']:\n",
        "        station_clim = station_climatology[station_climatology['Station'] == station_id]\n",
        "        if not station_clim.empty:\n",
        "            months = station_clim['Month'].values\n",
        "            temps = station_clim['Mean_Temp'].values\n",
        "            ax1.plot(months, temps, 'o-', color=station_colors[station_id], \n",
        "                    label=f'{station_id} ({stations[station_id][\"name\"]})', linewidth=2, markersize=6)\n",
        "    \n",
        "    ax1.set_title('Observed Monthly Temperature Climatology\\n1990-2014 Average', fontweight='bold')\n",
        "    ax1.set_xlabel('Month')\n",
        "    ax1.set_ylabel('Temperature (¬∞C)')\n",
        "    ax1.set_xticks(range(1, 13))\n",
        "    ax1.set_xticklabels(['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D'])\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(fontsize=9)\n",
        "    \n",
        "    # Data completeness\n",
        "    ax2 = axes[1]\n",
        "    stations_processed = []\n",
        "    data_completeness = []\n",
        "    \n",
        "    for station_id in ['AL0019', 'AL0035', 'AL0059']:\n",
        "        if station_id in station_climatology['Station'].values:\n",
        "            stations_processed.append(station_id)\n",
        "            station_data = station_climatology[station_climatology['Station'] == station_id]\n",
        "            avg_count = station_data['Count'].mean()\n",
        "            expected_days_per_month = 25 * 365.25 / 12\n",
        "            completeness = min(100, (avg_count / expected_days_per_month) * 100)\n",
        "            data_completeness.append(completeness)\n",
        "    \n",
        "    bars = ax2.bar(range(len(stations_processed)), data_completeness, \n",
        "                   color=[station_colors[sid] for sid in stations_processed], alpha=0.7, edgecolor='black')\n",
        "    \n",
        "    ax2.set_title('Station Data Quality\\n1990-2014 Period', fontweight='bold')\n",
        "    ax2.set_ylabel('Data Completeness (%)')\n",
        "    ax2.set_xlabel('Station')\n",
        "    ax2.set_xticks(range(len(stations_processed)))\n",
        "    ax2.set_xticklabels(stations_processed)\n",
        "    ax2.set_ylim(0, 105)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    for bar, pct in zip(bars, data_completeness):\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                f'{pct:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    fig.suptitle('Part 3: Station Data Processing Results', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nüéØ PART 3 SUMMARY\")\n",
        "    print(f\"‚úÖ Stations processed: {len(station_climatology['Station'].unique())}\")\n",
        "    print(f\"‚úÖ Total monthly records: {len(station_climatology)}\")\n",
        "    print(f\"‚úÖ Study period: 1990-2014 (25 years)\")\n",
        "    \n",
        "    print(f\"\\nüìä Station Data Quality:\")\n",
        "    for station_id in station_climatology['Station'].unique():\n",
        "        station_data = station_climatology[station_climatology['Station'] == station_id]\n",
        "        avg_temp = station_data['Mean_Temp'].mean()\n",
        "        print(f\"  {station_id}: avg temp {avg_temp:.1f}¬∞C\")\n",
        "    \n",
        "    print(f\"\\n‚û°Ô∏è Ready for Part 4: Model Validation\")\n",
        "else:\n",
        "    print(\"‚ùå Part 3 failed - no station data available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part4_header"
      },
      "source": [
        "# üéì Part 4: Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_functions"
      },
      "outputs": [],
      "source": [
        "def calculate_validation_metrics(model_temps, obs_temps):\n",
        "    \"\"\"Calculate the 5 validation metrics\"\"\"\n",
        "    \n",
        "    valid_mask = ~(np.isnan(model_temps) | np.isnan(obs_temps))\n",
        "    model_valid = model_temps[valid_mask]\n",
        "    obs_valid = obs_temps[valid_mask]\n",
        "    \n",
        "    if len(model_valid) < 3:\n",
        "        return None\n",
        "    \n",
        "    metrics = {}\n",
        "    \n",
        "    # 1. Root Mean Square Error (RMSE)\n",
        "    metrics['RMSE'] = np.sqrt(np.mean((model_valid - obs_valid) ** 2))\n",
        "    \n",
        "    # 2. Correlation coefficient (R)\n",
        "    metrics['R'] = np.corrcoef(model_valid, obs_valid)[0, 1]\n",
        "    \n",
        "    # 3. Nash-Sutcliffe Efficiency (NSE)\n",
        "    mean_obs = np.mean(obs_valid)\n",
        "    metrics['NSE'] = 1 - (np.sum((model_valid - obs_valid) ** 2) / \n",
        "                         np.sum((obs_valid - mean_obs) ** 2))\n",
        "    \n",
        "    # 4. Percent Bias (PBIAS)\n",
        "    metrics['PBIAS'] = 100 * (np.mean(model_valid - obs_valid) / np.mean(obs_valid))\n",
        "    \n",
        "    # 5. Mean Absolute Error (MAE)\n",
        "    metrics['MAE'] = np.mean(np.abs(model_valid - obs_valid))\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "def perform_validation(model_clim, station_clim):\n",
        "    \"\"\"Perform complete model validation\"\"\"\n",
        "    \n",
        "    print(f\"üéì PERFORMING MODEL VALIDATION\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    if model_clim is None or station_clim is None:\n",
        "        print(\"‚ùå Missing climatology data for validation\")\n",
        "        return None, None\n",
        "    \n",
        "    validation_results = []\n",
        "    models = model_clim['Model'].unique()\n",
        "    station_ids = station_clim['Station'].unique()\n",
        "    \n",
        "    for model in models:\n",
        "        for station_id in station_ids:\n",
        "            \n",
        "            print(f\"  üîÑ Validating {model} at {station_id}\")\n",
        "            \n",
        "            model_data = model_clim[(model_clim['Model'] == model) & \n",
        "                                  (model_clim['Station'] == station_id)]\n",
        "            \n",
        "            station_data = station_clim[station_clim['Station'] == station_id]\n",
        "            \n",
        "            if model_data.empty or station_data.empty:\n",
        "                print(f\"    ‚ùå No data available\")\n",
        "                continue\n",
        "            \n",
        "            model_temps = model_data['Mean_Temp'].values\n",
        "            obs_temps = station_data['Mean_Temp'].values\n",
        "            \n",
        "            metrics = calculate_validation_metrics(model_temps, obs_temps)\n",
        "            \n",
        "            if metrics is None:\n",
        "                print(f\"    ‚ùå Insufficient data for validation\")\n",
        "                continue\n",
        "            \n",
        "            result = {\n",
        "                'Model': model,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': stations[station_id]['name'],\n",
        "                **metrics\n",
        "            }\n",
        "            validation_results.append(result)\n",
        "            \n",
        "            print(f\"    ‚úÖ R={metrics['R']:.3f}, RMSE={metrics['RMSE']:.2f}¬∞C, NSE={metrics['NSE']:.3f}\")\n",
        "    \n",
        "    if not validation_results:\n",
        "        print(\"‚ùå No validation results generated\")\n",
        "        return None, None\n",
        "    \n",
        "    results_df = pd.DataFrame(validation_results)\n",
        "    \n",
        "    # Calculate model ranking\n",
        "    model_ranking = results_df.groupby('Model').agg({\n",
        "        'RMSE': 'mean',\n",
        "        'R': 'mean',\n",
        "        'NSE': 'mean', \n",
        "        'PBIAS': lambda x: np.mean(np.abs(x)),\n",
        "        'MAE': 'mean'\n",
        "    }).round(3)\n",
        "    \n",
        "    model_ranking['RMSE_rank'] = model_ranking['RMSE'].rank(ascending=True)\n",
        "    model_ranking['R_rank'] = model_ranking['R'].rank(ascending=False)\n",
        "    model_ranking['NSE_rank'] = model_ranking['NSE'].rank(ascending=False)\n",
        "    model_ranking['PBIAS_rank'] = model_ranking['PBIAS'].rank(ascending=True)\n",
        "    model_ranking['MAE_rank'] = model_ranking['MAE'].rank(ascending=True)\n",
        "    \n",
        "    rank_cols = ['RMSE_rank', 'R_rank', 'NSE_rank', 'PBIAS_rank', 'MAE_rank']\n",
        "    model_ranking['Average_Rank'] = model_ranking[rank_cols].mean(axis=1)\n",
        "    model_ranking = model_ranking.sort_values('Average_Rank')\n",
        "    \n",
        "    print(f\"\\n‚úÖ Part 4 Complete: {len(results_df)} validations performed\")\n",
        "    return results_df, model_ranking\n",
        "\n",
        "validation_results, model_ranking = perform_validation(model_climatology, station_climatology)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 4 comprehensive validation visualization\n",
        "if validation_results is not None and model_ranking is not None:\n",
        "    \n",
        "    print(\"üìä CREATING VALIDATION VISUALIZATION\")\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    \n",
        "    # 1. RMSE Heatmap\n",
        "    ax1 = axes[0, 0]\n",
        "    rmse_pivot = validation_results.pivot(index='Station', columns='Model', values='RMSE')\n",
        "    sns.heatmap(rmse_pivot, annot=True, fmt='.2f', cmap='Reds', ax=ax1, cbar_kws={'label': 'RMSE (¬∞C)'})\n",
        "    ax1.set_title('RMSE\\n(Lower is Better)', fontweight='bold')\n",
        "    \n",
        "    # 2. Correlation Heatmap\n",
        "    ax2 = axes[0, 1]\n",
        "    r_pivot = validation_results.pivot(index='Station', columns='Model', values='R')\n",
        "    sns.heatmap(r_pivot, annot=True, fmt='.3f', cmap='Blues', ax=ax2, cbar_kws={'label': 'Correlation (R)'})\n",
        "    ax2.set_title('Correlation\\n(Higher is Better)', fontweight='bold')\n",
        "    \n",
        "    # 3. NSE Heatmap\n",
        "    ax3 = axes[0, 2]\n",
        "    nse_pivot = validation_results.pivot(index='Station', columns='Model', values='NSE')\n",
        "    sns.heatmap(nse_pivot, annot=True, fmt='.3f', cmap='Greens', ax=ax3, cbar_kws={'label': 'NSE'})\n",
        "    ax3.set_title('Nash-Sutcliffe Efficiency\\n(Higher is Better)', fontweight='bold')\n",
        "    \n",
        "    # 4. PBIAS Heatmap\n",
        "    ax4 = axes[1, 0]\n",
        "    pbias_pivot = validation_results.pivot(index='Station', columns='Model', values='PBIAS')\n",
        "    sns.heatmap(pbias_pivot, annot=True, fmt='.1f', cmap='RdBu_r', center=0, ax=ax4, cbar_kws={'label': 'PBIAS (%)'})\n",
        "    ax4.set_title('Percent Bias\\n(Closer to 0 is Better)', fontweight='bold')\n",
        "    \n",
        "    # 5. Model Performance Box Plot\n",
        "    ax5 = axes[1, 1]\n",
        "    models = list(model_colors.keys())\n",
        "    rmse_data = [validation_results[validation_results['Model'] == model]['RMSE'].values for model in models]\n",
        "    bp = ax5.boxplot(rmse_data, labels=models, patch_artist=True)\n",
        "    for patch, model in zip(bp['boxes'], models):\n",
        "        patch.set_facecolor(model_colors[model])\n",
        "        patch.set_alpha(0.7)\n",
        "    ax5.set_title('RMSE Distribution\\nAcross All Stations', fontweight='bold')\n",
        "    ax5.set_ylabel('RMSE (¬∞C)')\n",
        "    ax5.tick_params(axis='x', rotation=45)\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 6. Model Ranking\n",
        "    ax6 = axes[1, 2]\n",
        "    models_ranked = model_ranking.index\n",
        "    ranks = model_ranking['Average_Rank'].values\n",
        "    colors_list = [model_colors[model] for model in models_ranked]\n",
        "    bars = ax6.barh(range(len(models_ranked)), ranks, color=colors_list, alpha=0.7)\n",
        "    ax6.set_yticks(range(len(models_ranked)))\n",
        "    ax6.set_yticklabels(models_ranked)\n",
        "    ax6.set_xlabel('Average Rank')\n",
        "    ax6.set_title('Model Performance Ranking\\n(Lower is Better)', fontweight='bold')\n",
        "    ax6.grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    for i, (bar, rank) in enumerate(zip(bars, ranks)):\n",
        "        ax6.text(rank + 0.05, bar.get_y() + bar.get_height()/2, \n",
        "                f'{rank:.2f}', ha='left', va='center', fontweight='bold')\n",
        "    \n",
        "    fig.suptitle('Part 4: Climate Model Validation Results\\nAMMAN ZARQA Basin, Jordan (1990-2014)', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.90)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ Validation visualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_results"
      },
      "source": [
        "# üéØ Workshop Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_final_results"
      },
      "outputs": [],
      "source": [
        "# Display final workshop results\n",
        "print(\"üéØ WORKSHOP RESULTS SUMMARY\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if validation_results is not None and model_ranking is not None:\n",
        "    print(f\"‚úÖ Validation completed: {len(validation_results)} model-station combinations\")\n",
        "    print(f\"‚úÖ Models evaluated: {len(validation_results['Model'].unique())}\")\n",
        "    print(f\"‚úÖ Stations evaluated: {len(validation_results['Station'].unique())}\")\n",
        "    \n",
        "    print(f\"\\nüèÜ MODEL RANKING (Best to Worst):\")\n",
        "    for i, (model, row) in enumerate(model_ranking.iterrows(), 1):\n",
        "        rmse = row['RMSE']\n",
        "        r = row['R']\n",
        "        nse = row['NSE']\n",
        "        print(f\"  {i}. {model}: RMSE={rmse:.2f}¬∞C, R={r:.3f}, NSE={nse:.3f}\")\n",
        "    \n",
        "    best_model = model_ranking.index[0]\n",
        "    worst_model = model_ranking.index[-1]\n",
        "    \n",
        "    print(f\"\\nüìä KEY FINDINGS:\")\n",
        "    print(f\"  ü•á Best performing model: {best_model}\")\n",
        "    print(f\"  üìâ Worst performing model: {worst_model}\")\n",
        "    print(f\"  üìè RMSE range: {validation_results['RMSE'].min():.2f} - {validation_results['RMSE'].max():.2f}¬∞C\")\n",
        "    print(f\"  üìà Correlation range: {validation_results['R'].min():.3f} - {validation_results['R'].max():.3f}\")\n",
        "    \n",
        "    print(f\"\\nüìã DETAILED VALIDATION RESULTS:\")\n",
        "    display(validation_results)\n",
        "    \n",
        "    print(f\"\\nüèÜ MODEL RANKING TABLE:\")\n",
        "    display(model_ranking[['RMSE', 'R', 'NSE', 'PBIAS', 'MAE', 'Average_Rank']])\n",
        "\n",
        "print(f\"\\nüéâ WORKSHOP COMPLETE!\")\n",
        "print(f\"üéì You have successfully validated climate models for AMMAN ZARQA Basin!\")\n",
        "print(f\"üìö Skills gained: NetCDF processing, climatology calculation, statistical validation\")\n",
        "print(f\"üîó Repository: https://github.com/MoawiahHussien/climate-model-validation-workshop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "# üéâ Workshop Conclusion\n",
        "\n",
        "## Congratulations!\n",
        "\n",
        "You have successfully completed the **Climate Model Validation Workshop**!\n",
        "\n",
        "### üéØ What You Accomplished:\n",
        "\n",
        "1. **üìç Data Extraction**: Downloaded and processed 6 climate model NetCDF files\n",
        "2. **üìä Climatology Calculation**: Converted daily data to monthly climatology patterns\n",
        "3. **üå°Ô∏è Station Processing**: Handled observed temperature data and quality control\n",
        "4. **üéì Model Validation**: Implemented 5 statistical validation metrics\n",
        "5. **üìà Visualization**: Created publication-quality analysis plots\n",
        "6. **üèÜ Model Ranking**: Identified best-performing climate models for your region\n",
        "\n",
        "### üí° Key Skills Gained:\n",
        "\n",
        "- **Python Climate Data Processing**: xarray, pandas, numpy\n",
        "- **Statistical Validation**: RMSE, R, NSE, PBIAS, MAE metrics\n",
        "- **Data Visualization**: matplotlib, seaborn plotting\n",
        "- **Climate Science**: Model evaluation and selection\n",
        "- **Research Workflow**: End-to-end validation pipeline\n",
        "\n",
        "### üåç Climate Science Insights:\n",
        "\n",
        "- Model grid resolution affects local representation\n",
        "- Different models show varying performance at different locations\n",
        "- Multiple validation metrics provide comprehensive assessment\n",
        "- Seasonal patterns are generally well captured by all models\n",
        "\n",
        "---\n",
        "üìß **Questions?** Contact the workshop instructor  \n",
        "üîó **Repository:** https://github.com/MoawiahHussien/climate-model-validation-workshop"
      ]
    }
  ]
}
