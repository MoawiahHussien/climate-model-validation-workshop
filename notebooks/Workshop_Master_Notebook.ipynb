{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workshop_header"
      },
      "source": [
        "# ğŸŒ¡ï¸ Climate Model Validation Workshop\n",
        "\n",
        "## Complete End-to-End Analysis\n",
        "**Study Area:** AMMAN ZARQA Basin, Jordan  \n",
        "**Models:** 6 RICCAR Climate Models (SSP4.5)  \n",
        "**Stations:** AL0019, AL0035, AL0059  \n",
        "**Period:** 1990-2014\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Workshop Overview\n",
        "\n",
        "### **Part 1: Station Data Extraction** ğŸ“\n",
        "- Download climate model NetCDF files\n",
        "- Extract temperature data at station locations\n",
        "\n",
        "### **Part 2: Monthly Climatology** ğŸ“Š\n",
        "- Convert daily data to monthly climatology\n",
        "- Calculate seasonal temperature patterns\n",
        "\n",
        "### **Part 3: Station Data Processing** ğŸŒ¡ï¸\n",
        "- Load observed temperature data\n",
        "- Process station climatology\n",
        "\n",
        "### **Part 4: Model Validation** ğŸ“\n",
        "- Calculate 5 validation metrics (RMSE, R, NSE, PBIAS, MAE)\n",
        "- Compare models against observations\n",
        "- Rank model performance\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“š Learning Objectives\n",
        "- âœ… Extract and process climate data using Python\n",
        "- âœ… Calculate validation metrics and interpret results\n",
        "- âœ… Create publication-quality visualizations\n",
        "- âœ… Make informed decisions about model selection\n",
        "\n",
        "**Estimated Time: 45-60 minutes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "# âš™ï¸ Setup: Install Packages and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "!pip install xarray netcdf4 requests tqdm seaborn -q\n",
        "print(\"âœ… Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"ğŸ“š Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_data"
      },
      "outputs": [],
      "source": [
        "def download_workshop_data():\n",
        "    \"\"\"Download all required files from GitHub repository\"\"\"\n",
        "    \n",
        "    print(\"ğŸ¯ DOWNLOADING WORKSHOP DATA\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    base_url = \"https://raw.githubusercontent.com/MoawiahHussien/climate-model-validation-workshop/main/\"\n",
        "    \n",
        "    os.makedirs(\"input_data/models_netcdf\", exist_ok=True)\n",
        "    os.makedirs(\"input_data/stations_data\", exist_ok=True)\n",
        "    \n",
        "    nc_files = [\n",
        "        \"arcgis_merged_Tmax_CMCC-CM2-SR5.nc\",\n",
        "        \"arcgis_merged_Tmax_CNRM-ESM2-1.nc\", \n",
        "        \"arcgis_merged_Tmax_EC-Earth3-Veg.nc\",\n",
        "        \"arcgis_merged_Tmax_IPSL-CM6A-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_MPI-ESM1-2-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_NorESM2-MM.nc\"\n",
        "    ]\n",
        "    \n",
        "    station_files = [\"AL0019.xlsx\", \"AL0035.xlsx\", \"AL0059.xlsx\"]\n",
        "    \n",
        "    print(\"ğŸ“¥ Downloading climate model files...\")\n",
        "    for nc_file in nc_files:\n",
        "        file_url = base_url + \"Input%20Files/Models.Nc.ArcGIS.Compatible/\" + nc_file\n",
        "        local_path = f\"input_data/models_netcdf/{nc_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"âœ… Using cached: {nc_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"ğŸ“¥ Downloading: {nc_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   âœ… Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Failed: {e}\")\n",
        "    \n",
        "    print(\"\\nğŸ“¥ Downloading station files...\")\n",
        "    for station_file in station_files:\n",
        "        file_url = base_url + \"Input%20Files/Stations.Daily/\" + station_file\n",
        "        local_path = f\"input_data/stations_data/{station_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"âœ… Using cached: {station_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"ğŸ“¥ Downloading: {station_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   âœ… Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Failed: {e}\")\n",
        "    \n",
        "    print(f\"\\nğŸ‰ Data download complete!\")\n",
        "\n",
        "download_workshop_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define_constants"
      },
      "outputs": [],
      "source": [
        "# Workshop configuration\n",
        "stations = {\n",
        "    'AL0019': {'lat': 31.95, 'lon': 35.93, 'name': 'Amman Airport'},\n",
        "    'AL0035': {'lat': 32.01, 'lon': 35.85, 'name': 'Zarqa Station'}, \n",
        "    'AL0059': {'lat': 31.97, 'lon': 36.12, 'name': 'Russeifa Station'}\n",
        "}\n",
        "\n",
        "model_files = {\n",
        "    'CMCC': 'arcgis_merged_Tmax_CMCC-CM2-SR5.nc',\n",
        "    'CNRM': 'arcgis_merged_Tmax_CNRM-ESM2-1.nc',\n",
        "    'EC-Earth3': 'arcgis_merged_Tmax_EC-Earth3-Veg.nc',\n",
        "    'IPSL': 'arcgis_merged_Tmax_IPSL-CM6A-LR.nc',\n",
        "    'MPI': 'arcgis_merged_Tmax_MPI-ESM1-2-LR.nc',\n",
        "    'NorESM2': 'arcgis_merged_Tmax_NorESM2-MM.nc'\n",
        "}\n",
        "\n",
        "model_colors = {\n",
        "    'CMCC': '#1f77b4', 'CNRM': '#ff7f0e', 'EC-Earth3': '#2ca02c',\n",
        "    'IPSL': '#d62728', 'MPI': '#9467bd', 'NorESM2': '#8c564b'\n",
        "}\n",
        "\n",
        "print(f\"ğŸ¯ WORKSHOP CONFIGURATION\")\n",
        "print(f\"ğŸ“ Target Stations: {len(stations)}\")\n",
        "print(f\"ğŸŒ¡ï¸ Climate Models: {len(model_files)}\")\n",
        "for station_id, info in stations.items():\n",
        "    print(f\"  {station_id}: {info['name']} ({info['lat']:.2f}Â°N, {info['lon']:.2f}Â°E)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1_header"
      },
      "source": [
        "# ğŸ“ Part 1: Station Data Extraction from Climate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_station_data"
      },
      "outputs": [],
      "source": [
        "def extract_station_data():\n",
        "    \"\"\"Extract temperature data at station locations from all models\"\"\"\n",
        "    \n",
        "    print(f\"ğŸ“ EXTRACTING DATA AT STATION LOCATIONS\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    model_station_data = {}\n",
        "    extraction_log = []\n",
        "    \n",
        "    for model_name, filename in model_files.items():\n",
        "        print(f\"\\nğŸ”„ Processing: {model_name}\")\n",
        "        \n",
        "        file_path = f\"input_data/models_netcdf/{filename}\"\n",
        "        \n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"    âŒ File not found: {filename}\")\n",
        "            continue\n",
        "        \n",
        "        ds = xr.open_dataset(file_path)\n",
        "        model_station_data[model_name] = {}\n",
        "        \n",
        "        for station_id, station_info in stations.items():\n",
        "            station_data = ds.tasmaxAdjust.sel(\n",
        "                lat=station_info['lat'], \n",
        "                lon=station_info['lon'], \n",
        "                method='nearest'\n",
        "            )\n",
        "            \n",
        "            grid_lat = float(station_data.lat.values)\n",
        "            grid_lon = float(station_data.lon.values)\n",
        "            distance_km = np.sqrt((grid_lat - station_info['lat'])**2 + \n",
        "                                (grid_lon - station_info['lon'])**2) * 111\n",
        "            \n",
        "            model_station_data[model_name][station_id] = station_data.values\n",
        "            \n",
        "            extraction_log.append({\n",
        "                'Model': model_name,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': station_info['name'],\n",
        "                'Distance_km': round(distance_km, 2),\n",
        "                'Days_Extracted': len(station_data),\n",
        "                'Valid_Days': int(np.sum(~np.isnan(station_data.values)))\n",
        "            })\n",
        "            \n",
        "            print(f\"    âœ… {station_id}: {len(station_data)} days, distance: {distance_km:.2f} km\")\n",
        "        \n",
        "        ds.close()\n",
        "    \n",
        "    print(f\"\\nâœ… Part 1 Complete: {len(extraction_log)} extractions\")\n",
        "    return model_station_data, pd.DataFrame(extraction_log)\n",
        "\n",
        "extracted_data, extraction_summary = extract_station_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "part1_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 1 visualization\n",
        "summary_data = []\n",
        "for model_name in extracted_data.keys():\n",
        "    for station_id in extracted_data[model_name].keys():\n",
        "        temp_data = extracted_data[model_name][station_id]\n",
        "        summary_data.append({\n",
        "            'Model': model_name,\n",
        "            'Station': station_id,\n",
        "            'Station_Name': stations[station_id]['name'],\n",
        "            'Mean_Temp': round(np.nanmean(temp_data), 2)\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Distance to grid points\n",
        "ax1 = axes[0]\n",
        "extraction_summary.boxplot(column='Distance_km', by='Station', ax=ax1)\n",
        "ax1.set_title('Distance to Nearest Grid Point\\n(Spatial Resolution Check)', fontweight='bold')\n",
        "ax1.set_ylabel('Distance (km)')\n",
        "ax1.set_xlabel('Station ID')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Temperature by model\n",
        "ax2 = axes[1]\n",
        "models = list(model_colors.keys())\n",
        "model_temps = [summary_df[summary_df['Model'] == model]['Mean_Temp'].values for model in models]\n",
        "bp = ax2.boxplot(model_temps, labels=models, patch_artist=True, widths=0.6)\n",
        "for patch, model in zip(bp['boxes'], models):\n",
        "    patch.set_facecolor(model_colors[model])\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax2.set_title('Mean Temperature by Model\\n1990-2014 Daily Average', fontweight='bold')\n",
        "ax2.set_ylabel('Temperature (Â°C)')\n",
        "ax2.set_xlabel('Climate Model')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "fig.suptitle('Part 1: Climate Model Data Extraction Results', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ¯ PART 1 SUMMARY\")\n",
        "print(f\"âœ… Models processed: {len(extracted_data)}\")\n",
        "print(f\"âœ… Stations extracted: {len(stations)}\")\n",
        "avg_distance = extraction_summary['Distance_km'].mean()\n",
        "print(f\"ğŸ“ Average grid distance: {avg_distance:.2f} km\")\n",
        "print(f\"\\nâ¡ï¸ Ready for Part 2: Monthly Climatology Calculation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2_header"
      },
      "source": [
        "# ğŸ“Š Part 2: Monthly Climatology Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "calculate_climatology"
      },
      "outputs": [],
      "source": [
        "def calculate_monthly_climatology_from_memory(extracted_data):\n",
        "    \"\"\"Calculate monthly climatology from extracted data in memory\"\"\"\n",
        "    \n",
        "    print(f\"ğŸ“Š CALCULATING MONTHLY CLIMATOLOGY\")\n",
        "    print(\"-\" * 35)\n",
        "    \n",
        "    climatology_data = []\n",
        "    \n",
        "    for model_name in extracted_data.keys():\n",
        "        for station_id in extracted_data[model_name].keys():\n",
        "            \n",
        "            print(f\"  ğŸ”„ Processing {model_name} - {station_id}\")\n",
        "            \n",
        "            temp_data = extracted_data[model_name][station_id]\n",
        "            time_index = pd.date_range('1990-01-01', periods=len(temp_data), freq='D')\n",
        "            \n",
        "            df = pd.DataFrame({\n",
        "                'Date': time_index,\n",
        "                'Temperature_C': temp_data\n",
        "            })\n",
        "            \n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            \n",
        "            monthly_clim = df.groupby('Month')['Temperature_C'].agg([\n",
        "                ('Mean_Temp', 'mean'),\n",
        "                ('Min_Temp', 'min'),\n",
        "                ('Max_Temp', 'max'),\n",
        "                ('Std_Temp', 'std')\n",
        "            ]).round(2)\n",
        "            \n",
        "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "            monthly_clim['Month_Name'] = month_names\n",
        "            monthly_clim['Model'] = model_name\n",
        "            monthly_clim['Station'] = station_id\n",
        "            monthly_clim['Station_Name'] = stations[station_id]['name']\n",
        "            monthly_clim = monthly_clim.reset_index()\n",
        "            \n",
        "            climatology_data.append(monthly_clim)\n",
        "    \n",
        "    all_climatology = pd.concat(climatology_data, ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nâœ… Part 2 Complete: Monthly climatology for {len(climatology_data)} model-station combinations\")\n",
        "    return all_climatology\n",
        "\n",
        "model_climatology = calculate_monthly_climatology_from_memory(extracted_data)\n",
        "\n",
        "if model_climatology is not None:\n",
        "    print(f\"\\nğŸ“Š Climatology Summary:\")\n",
        "    print(f\"  Total records: {len(model_climatology)}\")\n",
        "    print(f\"  Models: {model_climatology['Model'].nunique()}\")\n",
        "    print(f\"  Stations: {model_climatology['Station'].nunique()}\")\n",
        "    print(f\"  Temperature range: {model_climatology['Mean_Temp'].min():.1f}Â°C to {model_climatology['Mean_Temp'].max():.1f}Â°C\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "climatology_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 2 visualization\n",
        "if model_climatology is not None:\n",
        "    \n",
        "    print(f\"ğŸ“ˆ CREATING CLIMATOLOGY VISUALIZATION\")\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    stations_order = ['AL0019', 'AL0035', 'AL0059']\n",
        "    \n",
        "    for i, station_id in enumerate(stations_order):\n",
        "        ax = axes[i]\n",
        "        \n",
        "        for model in model_climatology['Model'].unique():\n",
        "            data = model_climatology[(model_climatology['Model'] == model) & \n",
        "                                    (model_climatology['Station'] == station_id)]\n",
        "            \n",
        "            if not data.empty:\n",
        "                months = data['Month'].values\n",
        "                temps = data['Mean_Temp'].values\n",
        "                \n",
        "                ax.plot(months, temps, 'o-', color=model_colors[model], \n",
        "                       label=model, linewidth=2, markersize=6, alpha=0.8)\n",
        "        \n",
        "        ax.set_title(f'{station_id}\\n({stations[station_id][\"name\"]})', fontweight='bold')\n",
        "        ax.set_xlabel('Month')\n",
        "        ax.set_ylabel('Temperature (Â°C)')\n",
        "        ax.set_xticks(range(1, 13))\n",
        "        ax.set_xticklabels(['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D'])\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        if i == 2:\n",
        "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "    \n",
        "    fig.suptitle('Part 2: Monthly Temperature Climatology by Station\\n1990-2014 Average (All Models)', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(right=0.85)\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nğŸ¯ PART 2 SUMMARY\")\n",
        "    print(f\"âœ… Monthly climatology calculated for {len(model_climatology['Model'].unique())} models\")\n",
        "    print(f\"âœ… {len(model_climatology['Station'].unique())} stations processed\")\n",
        "    print(f\"âœ… Temperature range: {model_climatology['Mean_Temp'].min():.1f}Â°C to {model_climatology['Mean_Temp'].max():.1f}Â°C\")\n",
        "    print(f\"\\nâ¡ï¸ Ready for Part 3: Station Data Processing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3_header"
      },
      "source": [
        "# ğŸŒ¡ï¸ Part 3: Station Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process_station_data"
      },
      "outputs": [],
      "source": [
        "def process_station_data():\n",
        "    \"\"\"Process observed station data for validation\"\"\"\n",
        "    \n",
        "    print(f\"ğŸŒ¡ï¸ PROCESSING STATION DATA\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    station_climatology = []\n",
        "    target_stations = ['AL0019', 'AL0035', 'AL0059']\n",
        "    \n",
        "    for station_id in target_stations:\n",
        "        station_file = f\"input_data/stations_data/{station_id}.xlsx\"\n",
        "        \n",
        "        if not os.path.exists(station_file):\n",
        "            print(f\"âŒ Station file not found: {station_id}.xlsx\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"ğŸ”„ Processing station: {station_id}\")\n",
        "        \n",
        "        try:\n",
        "            df = pd.read_excel(station_file)\n",
        "            \n",
        "            if 'Date' not in df.columns or 'Corrected Tmax' not in df.columns:\n",
        "                print(f\"âŒ Missing required columns in {station_id}\")\n",
        "                continue\n",
        "            \n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df = df[(df['Date'].dt.year >= 1990) & (df['Date'].dt.year <= 2014)]\n",
        "            df['Temperature'] = pd.to_numeric(df['Corrected Tmax'], errors='coerce')\n",
        "            df = df[(df['Temperature'] >= -20) & (df['Temperature'] <= 60)]\n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            \n",
        "            monthly_clim = df.groupby('Month')['Temperature'].agg([\n",
        "                ('Mean_Temp', 'mean'),\n",
        "                ('Min_Temp', 'min'),\n",
        "                ('Max_Temp', 'max'),\n",
        "                ('Std_Temp', 'std'),\n",
        "                ('Count', 'count')\n",
        "            ]).round(2)\n",
        "            \n",
        "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "            monthly_clim['Month_Name'] = month_names\n",
        "            monthly_clim['Station'] = station_id\n",
        "            monthly_clim['Station_Name'] = stations[station_id]['name']\n",
        "            monthly_clim = monthly_clim.reset_index()\n",
        "            \n",
        "            station_climatology.append(monthly_clim)\n",
        "            \n",
        "            valid_days = df['Temperature'].notna().sum()\n",
        "            total_days = len(df)\n",
        "            completeness = (valid_days / total_days) * 100\n",
        "            \n",
        "            print(f\"  âœ… {station_id}: {completeness:.1f}% data completeness\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ Error processing {station_id}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if station_climatology:\n",
        "        combined_station_clim = pd.concat(station_climatology, ignore_index=True)\n",
        "        print(f\"\\nâœ… Part 3 Complete: Station climatology for {len(station_climatology)} stations\")\n",
        "        return combined_station_clim\n",
        "    else:\n",
        "        print(\"âŒ No station data processed\")\n",
        "        return None\n",
        "\n",
        "station_climatology = process_station_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "station_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 3 visualization\n",
        "if station_climatology is not None:\n",
        "    \n",
        "    print(\"ğŸ“Š CREATING STATION VISUALIZATION\")\n",
        "    \n",
        "    station_colors = {'AL0019': '#1f77b4', 'AL0035': '#ff7f0e', 'AL0059': '#2ca02c'}\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # Monthly climatology\n",
        "    ax1 = axes[0]\n",
        "    for station_id in ['AL0019', 'AL0035', 'AL0059']:\n",
        "        station_clim = station_climatology[station_climatology['Station'] == station_id]\n",
        "        if not station_clim.empty:\n",
        "            months = station_clim['Month'].values\n",
        "            temps = station_clim['Mean_Temp'].values\n",
        "            ax1.plot(months, temps, 'o-', color=station_colors[station_id], \n",
        "                    label=f'{station_id} ({stations[station_id][\"name\"]})', linewidth=2, markersize=6)\n",
        "    \n",
        "    ax1.set_title('Observed Monthly Temperature Climatology\\n1990-2014 Average', fontweight='bold')\n",
        "    ax1.set_xlabel('Month')\n",
        "    ax1.set_ylabel('Temperature (Â°C)')\n",
        "    ax1.set_xticks(range(1, 13))\n",
        "    ax1.set_xticklabels(['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D'])\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(fontsize=9)\n",
        "    \n",
        "    # Data completeness\n",
        "    ax2 = axes[1]\n",
        "    stations_processed = []\n",
        "    data_completeness = []\n",
        "    \n",
        "    for station_id in ['AL0019', 'AL0035', 'AL0059']:\n",
        "        if station_id in station_climatology['Station'].values:\n",
        "            stations_processed.append(station_id)\n",
        "            station_data = station_climatology[station_climatology['Station'] == station_id]\n",
        "            avg_count = station_data['Count'].mean()\n",
        "            expected_days_per_month = 25 * 365.25 / 12\n",
        "            completeness = min(100, (avg_count / expected_days_per_month) * 100)\n",
        "            data_completeness.append(completeness)\n",
        "    \n",
        "    bars = ax2.bar(range(len(stations_processed)), data_completeness, \n",
        "                   color=[station_colors[sid] for sid in stations_processed], alpha=0.7, edgecolor='black')\n",
        "    \n",
        "    ax2.set_title('Station Data Quality\\n1990-2014 Period', fontweight='bold')\n",
        "    ax2.set_ylabel('Data Completeness (%)')\n",
        "    ax2.set_xlabel('Station')\n",
        "    ax2.set_xticks(range(len(stations_processed)))\n",
        "    ax2.set_xticklabels(stations_processed)\n",
        "    ax2.set_ylim(0, 105)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    for bar, pct in zip(bars, data_completeness):\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                f'{pct:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    fig.suptitle('Part 3: Station Data Processing Results', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nğŸ¯ PART 3 SUMMARY\")\n",
        "    print(f\"âœ… Stations processed: {len(station_climatology['Station'].unique())}\")\n",
        "    print(f\"âœ… Total monthly records: {len(station_climatology)}\")\n",
        "    print(f\"âœ… Study period: 1990-2014 (25 years)\")\n",
        "    \n",
        "    print(f\"\\nğŸ“Š Station Data Quality:\")\n",
        "    for station_id in station_climatology['Station'].unique():\n",
        "        station_data = station_climatology[station_climatology['Station'] == station_id]\n",
        "        avg_temp = station_data['Mean_Temp'].mean()\n",
        "        print(f\"  {station_id}: avg temp {avg_temp:.1f}Â°C\")\n",
        "    \n",
        "    print(f\"\\nâ¡ï¸ Ready for Part 4: Model Validation\")\n",
        "else:\n",
        "    print(\"âŒ Part 3 failed - no station data available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part4_header"
      },
      "source": [
        "# ğŸ“ Part 4: Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_functions"
      },
      "outputs": [],
      "source": [
        "def calculate_validation_metrics(model_temps, obs_temps):\n",
        "    \"\"\"Calculate the 5 validation metrics\"\"\"\n",
        "    \n",
        "    valid_mask = ~(np.isnan(model_temps) | np.isnan(obs_temps))\n",
        "    model_valid = model_temps[valid_mask]\n",
        "    obs_valid = obs_temps[valid_mask]\n",
        "    \n",
        "    if len(model_valid) < 3:\n",
        "        return None\n",
        "    \n",
        "    metrics = {}\n",
        "    \n",
        "    # 1. Root Mean Square Error (RMSE)\n",
        "    metrics['RMSE'] = np.sqrt(np.mean((model_valid - obs_valid) ** 2))\n",
        "    \n",
        "    # 2. Correlation coefficient (R)\n",
        "    metrics['R'] = np.corrcoef(model_valid, obs_valid)[0, 1]\n",
        "    \n",
        "    # 3. Nash-Sutcliffe Efficiency (NSE)\n",
        "    mean_obs = np.mean(obs_valid)\n",
        "    metrics['NSE'] = 1 - (np.sum((model_valid - obs_valid) ** 2) / \n",
        "                         np.sum((obs_valid - mean_obs) ** 2))\n",
        "    \n",
        "    # 4. Percent Bias (PBIAS)\n",
        "    metrics['PBIAS'] = 100 * (np.mean(model_valid - obs_valid) / np.mean(obs_valid))\n",
        "    \n",
        "    # 5. Mean Absolute Error (MAE)\n",
        "    metrics['MAE'] = np.mean(np.abs(model_valid - obs_valid))\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "def perform_validation(model_clim, station_clim):\n",
        "    \"\"\"Perform complete model validation\"\"\"\n",
        "    \n",
        "    print(f\"ğŸ“ PERFORMING MODEL VALIDATION\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    if model_clim is None or station_clim is None:\n",
        "        print(\"âŒ Missing climatology data for validation\")\n",
        "        return None, None\n",
        "    \n",
        "    validation_results = []\n",
        "    models = model_clim['Model'].unique()\n",
        "    station_ids = station_clim['Station'].unique()\n",
        "    \n",
        "    for model in models:\n",
        "        for station_id in station_ids:\n",
        "            \n",
        "            print(f\"  ğŸ”„ Validating {model} at {station_id}\")\n",
        "            \n",
        "            model_data = model_clim[(model_clim['Model'] == model) & \n",
        "                                  (model_clim['Station'] == station_id)]\n",
        "            \n",
        "            station_data = station_clim[station_clim['Station'] == station_id]\n",
        "            \n",
        "            if model_data.empty or station_data.empty:\n",
        "                print(f\"    âŒ No data available\")\n",
        "                continue\n",
        "            \n",
        "            model_temps = model_data['Mean_Temp'].values\n",
        "            obs_temps = station_data['Mean_Temp'].values\n",
        "            \n",
        "            metrics = calculate_validation_metrics(model_temps, obs_temps)\n",
        "            \n",
        "            if metrics is None:\n",
        "                print(f\"    âŒ Insufficient data for validation\")\n",
        "                continue\n",
        "            \n",
        "            result = {\n",
        "                'Model': model,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': stations[station_id]['name'],\n",
        "                **metrics\n",
        "            }\n",
        "            validation_results.append(result)\n",
        "            \n",
        "            print(f\"    âœ… R={metrics['R']:.3f}, RMSE={metrics['RMSE']:.2f}Â°C, NSE={metrics['NSE']:.3f}\")\n",
        "    \n",
        "    if not validation_results:\n",
        "        print(\"âŒ No validation results generated\")\n",
        "        return None, None\n",
        "    \n",
        "    results_df = pd.DataFrame(validation_results)\n",
        "    \n",
        "    # Calculate model ranking\n",
        "    model_ranking = results_df.groupby('Model').agg({\n",
        "        'RMSE': 'mean',\n",
        "        'R': 'mean',\n",
        "        'NSE': 'mean', \n",
        "        'PBIAS': lambda x: np.mean(np.abs(x)),\n",
        "        'MAE': 'mean'\n",
        "    }).round(3)\n",
        "    \n",
        "    model_ranking['RMSE_rank'] = model_ranking['RMSE'].rank(ascending=True)\n",
        "    model_ranking['R_rank'] = model_ranking['R'].rank(ascending=False)\n",
        "    model_ranking['NSE_rank'] = model_ranking['NSE'].rank(ascending=False)\n",
        "    model_ranking['PBIAS_rank'] = model_ranking['PBIAS'].rank(ascending=True)\n",
        "    model_ranking['MAE_rank'] = model_ranking['MAE'].rank(ascending=True)\n",
        "    \n",
        "    rank_cols = ['RMSE_rank', 'R_rank', 'NSE_rank', 'PBIAS_rank', 'MAE_rank']\n",
        "    model_ranking['Average_Rank'] = model_ranking[rank_cols].mean(axis=1)\n",
        "    model_ranking = model_ranking.sort_values('Average_Rank')\n",
        "    \n",
        "    print(f\"\\nâœ… Part 4 Complete: {len(results_df)} validations performed\")\n",
        "    return results_df, model_ranking\n",
        "\n",
        "validation_results, model_ranking = perform_validation(model_climatology, station_climatology)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 4 comprehensive validation visualization\n",
        "if validation_results is not None and model_ranking is not None:\n",
        "    \n",
        "    print(\"ğŸ“Š CREATING VALIDATION VISUALIZATION\")\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    \n",
        "    # 1. RMSE Heatmap\n",
        "    ax1 = axes[0, 0]\n",
        "    rmse_pivot = validation_results.pivot(index='Station', columns='Model', values='RMSE')\n",
        "    sns.heatmap(rmse_pivot, annot=True, fmt='.2f', cmap='Reds', ax=ax1, cbar_kws={'label': 'RMSE (Â°C)'})\n",
        "    ax1.set_title('RMSE\\n(Lower is Better)', fontweight='bold')\n",
        "    \n",
        "    # 2. Correlation Heatmap\n",
        "    ax2 = axes[0, 1]\n",
        "    r_pivot = validation_results.pivot(index='Station', columns='Model', values='R')\n",
        "    sns.heatmap(r_pivot, annot=True, fmt='.3f', cmap='Blues', ax=ax2, cbar_kws={'label': 'Correlation (R)'})\n",
        "    ax2.set_title('Correlation\\n(Higher is Better)', fontweight='bold')\n",
        "    \n",
        "    # 3. NSE Heatmap\n",
        "    ax3 = axes[0, 2]\n",
        "    nse_pivot = validation_results.pivot(index='Station', columns='Model', values='NSE')\n",
        "    sns.heatmap(nse_pivot, annot=True, fmt='.3f', cmap='Greens', ax=ax3, cbar_kws={'label': 'NSE'})\n",
        "    ax3.set_title('Nash-Sutcliffe Efficiency\\n(Higher is Better)', fontweight='bold')\n",
        "    \n",
        "    # 4. PBIAS Heatmap\n",
        "    ax4 = axes[1, 0]\n",
        "    pbias_pivot = validation_results.pivot(index='Station', columns='Model', values='PBIAS')\n",
        "    sns.heatmap(pbias_pivot, annot=True, fmt='.1f', cmap='RdBu_r', center=0, ax=ax4, cbar_kws={'label': 'PBIAS (%)'})\n",
        "    ax4.set_title('Percent Bias\\n(Closer to 0 is Better)', fontweight='bold')\n",
        "    \n",
        "    # 5. Model Performance Box Plot\n",
        "    ax5 = axes[1, 1]\n",
        "    models = list(model_colors.keys())\n",
        "    rmse_data = [validation_results[validation_results['Model'] == model]['RMSE'].values for model in models]\n",
        "    bp = ax5.boxplot(rmse_data, labels=models, patch_artist=True)\n",
        "    for patch, model in zip(bp['boxes'], models):\n",
        "        patch.set_facecolor(model_colors[model])\n",
        "        patch.set_alpha(0.7)\n",
        "    ax5.set_title('RMSE Distribution\\nAcross All Stations', fontweight='bold')\n",
        "    ax5.set_ylabel('RMSE (Â°C)')\n",
        "    ax5.tick_params(axis='x', rotation=45)\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 6. Model Ranking\n",
        "    ax6 = axes[1, 2]\n",
        "    models_ranked = model_ranking.index\n",
        "    ranks = model_ranking['Average_Rank'].values\n",
        "    colors_list = [model_colors[model] for model in models_ranked]\n",
        "    bars = ax6.barh(range(len(models_ranked)), ranks, color=colors_list, alpha=0.7)\n",
        "    ax6.set_yticks(range(len(models_ranked)))\n",
        "    ax6.set_yticklabels(models_ranked)\n",
        "    ax6.set_xlabel('Average Rank')\n",
        "    ax6.set_title('Model Performance Ranking\\n(Lower is Better)', fontweight='bold')\n",
        "    ax6.grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    for i, (bar, rank) in enumerate(zip(bars, ranks)):\n",
        "        ax6.text(rank + 0.05, bar.get_y() + bar.get_height()/2, \n",
        "                f'{rank:.2f}', ha='left', va='center', fontweight='bold')\n",
        "    \n",
        "    fig.suptitle('Part 4: Climate Model Validation Results\\nAMMAN ZARQA Basin, Jordan (1990-2014)', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.90)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"âœ… Validation visualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_results"
      },
      "source": [
        "# ğŸ¯ Workshop Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_final_results"
      },
      "outputs": [],
      "source": [
        "# Display final workshop results\n",
        "print(\"ğŸ¯ WORKSHOP RESULTS SUMMARY\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if validation_results is not None and model_ranking is not None:\n",
        "    print(f\"âœ… Validation completed: {len(validation_results)} model-station combinations\")\n",
        "    print(f\"âœ… Models evaluated: {len(validation_results['Model'].unique())}\")\n",
        "    print(f\"âœ… Stations evaluated: {len(validation_results['Station'].unique())}\")\n",
        "    \n",
        "    print(f\"\\nğŸ† MODEL RANKING (Best to Worst):\")\n",
        "    for i, (model, row) in enumerate(model_ranking.iterrows(), 1):\n",
        "        rmse = row['RMSE']\n",
        "        r = row['R']\n",
        "        nse = row['NSE']\n",
        "        print(f\"  {i}. {model}: RMSE={rmse:.2f}Â°C, R={r:.3f}, NSE={nse:.3f}\")\n",
        "    \n",
        "    best_model = model_ranking.index[0]\n",
        "    worst_model = model_ranking.index[-1]\n",
        "    \n",
        "    print(f\"\\nğŸ“Š KEY FINDINGS:\")\n",
        "    print(f\"  ğŸ¥‡ Best performing model: {best_model}\")\n",
        "    print(f\"  ğŸ“‰ Worst performing model: {worst_model}\")\n",
        "    print(f\"  ğŸ“ RMSE range: {validation_results['RMSE'].min():.2f} - {validation_results['RMSE'].max():.2f}Â°C\")\n",
        "    print(f\"  ğŸ“ˆ Correlation range: {validation_results['R'].min():.3f} - {validation_results['R'].max():.3f}\")\n",
        "    \n",
        "    print(f\"\\nğŸ“‹ DETAILED VALIDATION RESULTS:\")\n",
        "    display(validation_results)\n",
        "    \n",
        "    print(f\"\\nğŸ† MODEL RANKING TABLE:\")\n",
        "    display(model_ranking[['RMSE', 'R', 'NSE', 'PBIAS', 'MAE', 'Average_Rank']])\n",
        "\n",
        "print(f\"\\nğŸ‰ WORKSHOP COMPLETE!\")\n",
        "print(f\"ğŸ“ You have successfully validated climate models for AMMAN ZARQA Basin!\")\n",
        "print(f\"ğŸ“š Skills gained: NetCDF processing, climatology calculation, statistical validation\")\n",
        "print(f\"ğŸ”— Repository: https://github.com/MoawiahHussien/climate-model-validation-workshop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "# ğŸ‰ Workshop Conclusion\n",
        "\n",
        "## Congratulations!\n",
        "\n",
        "You have successfully completed the **Climate Model Validation Workshop**!\n",
        "\n",
        "### ğŸ¯ What You Accomplished:\n",
        "\n",
        "1. **ğŸ“ Data Extraction**: Downloaded and processed 6 climate model NetCDF files\n",
        "2. **ğŸ“Š Climatology Calculation**: Converted daily data to monthly climatology patterns\n",
        "3. **ğŸŒ¡ï¸ Station Processing**: Handled observed temperature data and quality control\n",
        "4. **ğŸ“ Model Validation**: Implemented 5 statistical validation metrics\n",
        "5. **ğŸ“ˆ Visualization**: Created publication-quality analysis plots\n",
        "6. **ğŸ† Model Ranking**: Identified best-performing climate models for your region\n",
        "\n",
        "### ğŸ’¡ Key Skills Gained:\n",
        "\n",
        "- **Python Climate Data Processing**: xarray, pandas, numpy\n",
        "- **Statistical Validation**: RMSE, R, NSE, PBIAS, MAE metrics\n",
        "- **Data Visualization**: matplotlib, seaborn plotting\n",
        "- **Climate Science**: Model evaluation and selection\n",
        "- **Research Workflow**: End-to-end validation pipeline\n",
        "\n",
        "### ğŸŒ Climate Science Insights:\n",
        "\n",
        "- Model grid resolution affects local representation\n",
        "- Different models show varying performance at different locations\n",
        "- Multiple validation metrics provide comprehensive assessment\n",
        "- Seasonal patterns are generally well captured by all models\n",
        "\n",
        "---\n",
        "ğŸ“§ **Questions?** Contact the workshop instructor  \n",
        "ğŸ”— **Repository:** https://github.com/MoawiahHussien/climate-model-validation-workshop"
      ]
    }
  ]
}
