{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workshop_header"
      },
      "source": [
        "# üå°Ô∏è Climate Model Validation Workshop\n",
        "\n",
        "## Complete End-to-End Analysis\n",
        "**Study Area:** AMMAN ZARQA Basin, Jordan  \n",
        "**Models:** 6 RICCAR Climate Models (SSP4.5)  \n",
        "**Stations:** AL0019, AL0035, AL0059  \n",
        "**Period:** 1990-2014\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Workshop Overview\n",
        "\n",
        "### **Part 1: Station Data Extraction** üìç\n",
        "- Download climate model NetCDF files\n",
        "- Extract temperature data at station locations\n",
        "\n",
        "### **Part 2: Monthly Climatology** üìä\n",
        "- Convert daily data to monthly climatology\n",
        "- Calculate seasonal temperature patterns\n",
        "\n",
        "### **Part 3: Station Data Processing** üå°Ô∏è\n",
        "- Load observed temperature data\n",
        "- Process station climatology\n",
        "\n",
        "### **Part 4: Model Validation** üéì\n",
        "- Calculate 5 validation metrics (RMSE, R, NSE, PBIAS, MAE)\n",
        "- Compare models against observations\n",
        "- Rank model performance\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Learning Objectives\n",
        "- ‚úÖ Extract and process climate data using Python\n",
        "- ‚úÖ Calculate validation metrics and interpret results\n",
        "- ‚úÖ Create publication-quality visualizations\n",
        "- ‚úÖ Make informed decisions about model selection\n",
        "\n",
        "**Estimated Time: 45-60 minutes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "# ‚öôÔ∏è Setup: Install Packages and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "!pip install xarray netcdf4 requests tqdm seaborn -q\n",
        "print(\"‚úÖ Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"üìö Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_data"
      },
      "outputs": [],
      "source": [
        "def download_workshop_data():\n",
        "    \"\"\"Download all required files from GitHub repository\"\"\"\n",
        "    \n",
        "    print(\"üéØ DOWNLOADING WORKSHOP DATA\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    base_url = \"https://raw.githubusercontent.com/MoawiahHussien/climate-model-validation-workshop/main/\"\n",
        "    \n",
        "    os.makedirs(\"input_data/models_netcdf\", exist_ok=True)\n",
        "    os.makedirs(\"input_data/stations_data\", exist_ok=True)\n",
        "    \n",
        "    nc_files = [\n",
        "        \"arcgis_merged_Tmax_CMCC-CM2-SR5.nc\",\n",
        "        \"arcgis_merged_Tmax_CNRM-ESM2-1.nc\", \n",
        "        \"arcgis_merged_Tmax_EC-Earth3-Veg.nc\",\n",
        "        \"arcgis_merged_Tmax_IPSL-CM6A-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_MPI-ESM1-2-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_NorESM2-MM.nc\"\n",
        "    ]\n",
        "    \n",
        "    station_files = [\"AL0019.xlsx\", \"AL0035.xlsx\", \"AL0059.xlsx\"]\n",
        "    \n",
        "    print(\"üì• Downloading climate model files...\")\n",
        "    for nc_file in nc_files:\n",
        "        file_url = base_url + \"Input%20Files/Models.Nc.ArcGIS.Compatible/\" + nc_file\n",
        "        local_path = f\"input_data/models_netcdf/{nc_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"‚úÖ Using cached: {nc_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"üì• Downloading: {nc_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   ‚úÖ Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Failed: {e}\")\n",
        "    \n",
        "    print(\"\\nüì• Downloading station files...\")\n",
        "    for station_file in station_files:\n",
        "        file_url = base_url + \"Input%20Files/Stations.Daily/\" + station_file\n",
        "        local_path = f\"input_data/stations_data/{station_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"‚úÖ Using cached: {station_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"üì• Downloading: {station_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   ‚úÖ Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Failed: {e}\")\n",
        "    \n",
        "    print(f\"\\nüéâ Data download complete!\")\n",
        "\n",
        "download_workshop_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define_constants"
      },
      "outputs": [],
      "source": [
        "# Workshop configuration\n",
        "stations = {\n",
        "    'AL0019': {'lat': 31.95, 'lon': 35.93, 'name': 'Amman Airport'},\n",
        "    'AL0035': {'lat': 32.01, 'lon': 35.85, 'name': 'Zarqa Station'}, \n",
        "    'AL0059': {'lat': 31.97, 'lon': 36.12, 'name': 'Russeifa Station'}\n",
        "}\n",
        "\n",
        "model_files = {\n",
        "    'CMCC': 'arcgis_merged_Tmax_CMCC-CM2-SR5.nc',\n",
        "    'CNRM': 'arcgis_merged_Tmax_CNRM-ESM2-1.nc',\n",
        "    'EC-Earth3': 'arcgis_merged_Tmax_EC-Earth3-Veg.nc',\n",
        "    'IPSL': 'arcgis_merged_Tmax_IPSL-CM6A-LR.nc',\n",
        "    'MPI': 'arcgis_merged_Tmax_MPI-ESM1-2-LR.nc',\n",
        "    'NorESM2': 'arcgis_merged_Tmax_NorESM2-MM.nc'\n",
        "}\n",
        "\n",
        "model_colors = {\n",
        "    'CMCC': '#1f77b4', 'CNRM': '#ff7f0e', 'EC-Earth3': '#2ca02c',\n",
        "    'IPSL': '#d62728', 'MPI': '#9467bd', 'NorESM2': '#8c564b'\n",
        "}\n",
        "\n",
        "print(f\"üéØ WORKSHOP CONFIGURATION\")\n",
        "print(f\"üìç Target Stations: {len(stations)}\")\n",
        "print(f\"üå°Ô∏è Climate Models: {len(model_files)}\")\n",
        "for station_id, info in stations.items():\n",
        "    print(f\"  {station_id}: {info['name']} ({info['lat']:.2f}¬∞N, {info['lon']:.2f}¬∞E)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1_header"
      },
      "source": [
        "# üìç Part 1: Station Data Extraction from Climate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_station_data"
      },
      "outputs": [],
      "source": [
        "def extract_station_data():\n",
        "    \"\"\"Extract temperature data at station locations from all models\"\"\"\n",
        "    \n",
        "    print(f\"üìç EXTRACTING DATA AT STATION LOCATIONS\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    model_station_data = {}\n",
        "    extraction_log = []\n",
        "    \n",
        "    for model_name, filename in model_files.items():\n",
        "        print(f\"\\nüîÑ Processing: {model_name}\")\n",
        "        \n",
        "        file_path = f\"input_data/models_netcdf/{filename}\"\n",
        "        \n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"    ‚ùå File not found: {filename}\")\n",
        "            continue\n",
        "        \n",
        "        ds = xr.open_dataset(file_path)\n",
        "        model_station_data[model_name] = {}\n",
        "        \n",
        "        for station_id, station_info in stations.items():\n",
        "            station_data = ds.tasmaxAdjust.sel(\n",
        "                lat=station_info['lat'], \n",
        "                lon=station_info['lon'], \n",
        "                method='nearest'\n",
        "            )\n",
        "            \n",
        "            grid_lat = float(station_data.lat.values)\n",
        "            grid_lon = float(station_data.lon.values)\n",
        "            distance_km = np.sqrt((grid_lat - station_info['lat'])**2 + \n",
        "                                (grid_lon - station_info['lon'])**2) * 111\n",
        "            \n",
        "            model_station_data[model_name][station_id] = station_data.values\n",
        "            \n",
        "            extraction_log.append({\n",
        "                'Model': model_name,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': station_info['name'],\n",
        "                'Distance_km': round(distance_km, 2),\n",
        "                'Days_Extracted': len(station_data),\n",
        "                'Valid_Days': int(np.sum(~np.isnan(station_data.values)))\n",
        "            })\n",
        "            \n",
        "            print(f\"    ‚úÖ {station_id}: {len(station_data)} days, distance: {distance_km:.2f} km\")\n",
        "        \n",
        "        ds.close()\n",
        "    \n",
        "    print(f\"\\n‚úÖ Part 1 Complete: {len(extraction_log)} extractions\")\n",
        "    return model_station_data, pd.DataFrame(extraction_log)\n",
        "\n",
        "extracted_data, extraction_summary = extract_station_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "part1_visualization"
      },
      "outputs": [],
      "source": [
        "# Part 1 visualization\n",
        "summary_data = []\n",
        "for model_name in extracted_data.keys():\n",
        "    for station_id in extracted_data[model_name].keys():\n",
        "        temp_data = extracted_data[model_name][station_id]\n",
        "        summary_data.append({\n",
        "            'Model': model_name,\n",
        "            'Station': station_id,\n",
        "            'Station_Name': stations[station_id]['name'],\n",
        "            'Mean_Temp': round(np.nanmean(temp_data), 2)\n",
        "        })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Distance to grid points\n",
        "ax1 = axes[0]\n",
        "extraction_summary.boxplot(column='Distance_km', by='Station', ax=ax1)\n",
        "ax1.set_title('Distance to Nearest Grid Point\\n(Spatial Resolution Check)', fontweight='bold')\n",
        "ax1.set_ylabel('Distance (km)')\n",
        "ax1.set_xlabel('Station ID')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Temperature by model\n",
        "ax2 = axes[1]\n",
        "models = list(model_colors.keys())\n",
        "model_temps = [summary_df[summary_df['Model'] == model]['Mean_Temp'].values for model in models]\n",
        "bp = ax2.boxplot(model_temps, labels=models, patch_artist=True, widths=0.6)\n",
        "for patch, model in zip(bp['boxes'], models):\n",
        "    patch.set_facecolor(model_colors[model])\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax2.set_title('Mean Temperature by Model\\n1990-2014 Daily Average', fontweight='bold')\n",
        "ax2.set_ylabel('Temperature (¬∞C)')\n",
        "ax2.set_xlabel('Climate Model')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "fig.suptitle('Part 1: Climate Model Data Extraction Results', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüéØ PART 1 SUMMARY\")\n",
        "print(f\"‚úÖ Models processed: {len(extracted_data)}\")\n",
        "print(f\"‚úÖ Stations extracted: {len(stations)}\")\n",
        "avg_distance = extraction_summary['Distance_km'].mean()\n",
        "print(f\"üìè Average grid distance: {avg_distance:.2f} km\")\n",
        "print(f\"\\n‚û°Ô∏è Ready for Part 2: Monthly Climatology Calculation\")"
      ]
    }"
  ]
}
