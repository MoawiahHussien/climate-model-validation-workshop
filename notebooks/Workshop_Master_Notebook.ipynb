{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workshop_header"
      },
      "source": [
        "# ğŸŒ¡ï¸ Climate Model Validation Workshop\n",
        "\n",
        "## Complete End-to-End Analysis\n",
        "**Study Area:** AMMAN ZARQA Basin, Jordan  \n",
        "**Models:** 6 RICCAR Climate Models (SSP4.5)  \n",
        "**Stations:** AL0019, AL0035, AL0059  \n",
        "**Period:** 1990-2014\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Workshop Overview\n",
        "\n",
        "### **Part 1: Station Data Extraction** ğŸ“\n",
        "- Download climate model NetCDF files\n",
        "- Extract temperature data at station locations\n",
        "\n",
        "### **Part 2: Monthly Climatology** ğŸ“Š\n",
        "- Convert daily data to monthly climatology\n",
        "- Calculate seasonal temperature patterns\n",
        "\n",
        "### **Part 3: Station Data Processing** ğŸŒ¡ï¸\n",
        "- Load observed temperature data\n",
        "- Process station climatology\n",
        "\n",
        "### **Part 4: Model Validation** ğŸ“\n",
        "- Calculate 5 validation metrics (RMSE, R, NSE, PBIAS, MAE)\n",
        "- Compare models against observations\n",
        "- Rank model performance\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“š Learning Objectives\n",
        "- âœ… Extract and process climate data using Python\n",
        "- âœ… Calculate validation metrics and interpret results\n",
        "- âœ… Create publication-quality visualizations\n",
        "- âœ… Make informed decisions about model selection\n",
        "\n",
        "**Estimated Time: 45-60 minutes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "# âš™ï¸ Setup: Install Packages and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "!pip install xarray netcdf4 requests tqdm seaborn -q\n",
        "print(\"âœ… Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"ğŸ“š Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_data"
      },
      "outputs": [],
      "source": [
        "def download_workshop_data():\n",
        "    print(\"ğŸ¯ DOWNLOADING WORKSHOP DATA\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    base_url = \"https://raw.githubusercontent.com/MoawiahHussien/climate-model-validation-workshop/main/\"\n",
        "    \n",
        "    os.makedirs(\"input_data/models_netcdf\", exist_ok=True)\n",
        "    os.makedirs(\"input_data/stations_data\", exist_ok=True)\n",
        "    \n",
        "    nc_files = [\n",
        "        \"arcgis_merged_Tmax_CMCC-CM2-SR5.nc\",\n",
        "        \"arcgis_merged_Tmax_CNRM-ESM2-1.nc\", \n",
        "        \"arcgis_merged_Tmax_EC-Earth3-Veg.nc\",\n",
        "        \"arcgis_merged_Tmax_IPSL-CM6A-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_MPI-ESM1-2-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_NorESM2-MM.nc\"\n",
        "    ]\n",
        "    \n",
        "    station_files = [\"AL0019.xlsx\", \"AL0035.xlsx\", \"AL0059.xlsx\"]\n",
        "    \n",
        "    print(\"ğŸ“¥ Downloading climate model files...\")\n",
        "    for nc_file in nc_files:\n",
        "        file_url = base_url + \"Input%20Files/Models.Nc.ArcGIS.Compatible/\" + nc_file\n",
        "        local_path = f\"input_data/models_netcdf/{nc_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"âœ… Using cached: {nc_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"ğŸ“¥ Downloading: {nc_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   âœ… Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Failed: {e}\")\n",
        "    \n",
        "    print(\"\\nğŸ“¥ Downloading station files...\")\n",
        "    for station_file in station_files:\n",
        "        file_url = base_url + \"Input%20Files/Stations.Daily/\" + station_file\n",
        "        local_path = f\"input_data/stations_data/{station_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"âœ… Using cached: {station_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"ğŸ“¥ Downloading: {station_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   âœ… Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Failed: {e}\")\n",
        "    \n",
        "    print(f\"\\nğŸ‰ Data download complete!\")\n",
        "\n",
        "download_workshop_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define_constants"
      },
      "outputs": [],
      "source": [
        "stations = {\n",
        "    'AL0019': {'lat': 31.95, 'lon': 35.93, 'name': 'Amman Airport'},\n",
        "    'AL0035': {'lat': 32.01, 'lon': 35.85, 'name': 'Zarqa Station'}, \n",
        "    'AL0059': {'lat': 31.97, 'lon': 36.12, 'name': 'Russeifa Station'}\n",
        "}\n",
        "\n",
        "model_files = {\n",
        "    'CMCC': 'arcgis_merged_Tmax_CMCC-CM2-SR5.nc',\n",
        "    'CNRM': 'arcgis_merged_Tmax_CNRM-ESM2-1.nc',\n",
        "    'EC-Earth3': 'arcgis_merged_Tmax_EC-Earth3-Veg.nc',\n",
        "    'IPSL': 'arcgis_merged_Tmax_IPSL-CM6A-LR.nc',\n",
        "    'MPI': 'arcgis_merged_Tmax_MPI-ESM1-2-LR.nc',\n",
        "    'NorESM2': 'arcgis_merged_Tmax_NorESM2-MM.nc'\n",
        "}\n",
        "\n",
        "model_colors = {\n",
        "    'CMCC': '#1f77b4', 'CNRM': '#ff7f0e', 'EC-Earth3': '#2ca02c',\n",
        "    'IPSL': '#d62728', 'MPI': '#9467bd', 'NorESM2': '#8c564b'\n",
        "}\n",
        "\n",
        "print(f\"ğŸ¯ WORKSHOP CONFIGURATION\")\n",
        "print(f\"ğŸ“ Target Stations: {len(stations)}\")\n",
        "print(f\"ğŸŒ¡ï¸ Climate Models: {len(model_files)}\")\n",
        "for station_id, info in stations.items():\n",
        "    print(f\"  {station_id}: {info['name']} ({info['lat']:.2f}Â°N, {info['lon']:.2f}Â°E)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1_header"
      },
      "source": [
        "# ğŸ“ Part 1: Station Data Extraction from Climate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_station_data"
      },
      "outputs": [],
      "source": [
        "def extract_station_data():\n",
        "    print(f\"ğŸ“ EXTRACTING DATA AT STATION LOCATIONS\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    model_station_data = {}\n",
        "    extraction_log = []\n",
        "    \n",
        "    for model_name, filename in model_files.items():\n",
        "        print(f\"\\nğŸ”„ Processing: {model_name}\")\n",
        "        \n",
        "        file_path = f\"input_data/models_netcdf/{filename}\"\n",
        "        \n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"    âŒ File not found: {filename}\")\n",
        "            continue\n",
        "        \n",
        "        ds = xr.open_dataset(file_path)\n",
        "        model_station_data[model_name] = {}\n",
        "        \n",
        "        for station_id, station_info in stations.items():\n",
        "            station_data = ds.tasmaxAdjust.sel(\n",
        "                lat=station_info['lat'], \n",
        "                lon=station_info['lon'], \n",
        "                method='nearest'\n",
        "            )\n",
        "            \n",
        "            grid_lat = float(station_data.lat.values)\n",
        "            grid_lon = float(station_data.lon.values)\n",
        "            distance_km = np.sqrt((grid_lat - station_info['lat'])**2 + \n",
        "                                (grid_lon - station_info['lon'])**2) * 111\n",
        "            \n",
        "            model_station_data[model_name][station_id] = station_data.values\n",
        "            \n",
        "            extraction_log.append({\n",
        "                'Model': model_name,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': station_info['name'],\n",
        "                'Distance_km': round(distance_km, 2),\n",
        "                'Days_Extracted': len(station_data),\n",
        "                'Valid_Days': int(np.sum(~np.isnan(station_data.values)))\n",
        "            })\n",
        "            \n",
        "            print(f\"    âœ… {station_id}: {len(station_data)} days, distance: {distance_km:.2f} km\")\n",
        "        \n",
        "        ds.close()\n",
        "    \n",
        "    print(f\"\\nâœ… Part 1 Complete: {len(extraction_log)} extractions\")\n",
        "    return model_station_data, pd.DataFrame(extraction_log)\n",
        "\n",
        "extracted_data, extraction_summary = extract_station_data()\n",
        "print(f\"\\nâ¡ï¸ Ready for Part 2: Monthly Climatology Calculation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2_header"
      },
      "source": [
        "# ğŸ“Š Part 2: Monthly Climatology Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "calculate_climatology"
      },
      "outputs": [],
      "source": [
        "def calculate_monthly_climatology_from_memory(extracted_data):\n",
        "    print(f\"ğŸ“Š CALCULATING MONTHLY CLIMATOLOGY\")\n",
        "    print(\"-\" * 35)\n",
        "    \n",
        "    climatology_data = []\n",
        "    \n",
        "    for model_name in extracted_data.keys():\n",
        "        for station_id in extracted_data[model_name].keys():\n",
        "            \n",
        "            print(f\"  ğŸ”„ Processing {model_name} - {station_id}\")\n",
        "            \n",
        "            temp_data = extracted_data[model_name][station_id]\n",
        "            time_index = pd.date_range('1990-01-01', periods=len(temp_data), freq='D')\n",
        "            \n",
        "            df = pd.DataFrame({\n",
        "                'Date': time_index,\n",
        "                'Temperature_C': temp_data\n",
        "            })\n",
        "            \n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            \n",
        "            monthly_clim = df.groupby('Month')['Temperature_C'].agg([\n",
        "                ('Mean_Temp', 'mean'),\n",
        "                ('Min_Temp', 'min'),\n",
        "                ('Max_Temp', 'max'),\n",
        "                ('Std_Temp', 'std')\n",
        "            ]).round(2)\n",
        "            \n",
        "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "            monthly_clim['Month_Name'] = month_names\n",
        "            monthly_clim['Model'] = model_name\n",
        "            monthly_clim['Station'] = station_id\n",
        "            monthly_clim['Station_Name'] = stations[station_id]['name']\n",
        "            monthly_clim = monthly_clim.reset_index()\n",
        "            \n",
        "            climatology_data.append(monthly_clim)\n",
        "    \n",
        "    all_climatology = pd.concat(climatology_data, ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nâœ… Part 2 Complete: Monthly climatology for {len(climatology_data)} model-station combinations\")\n",
        "    return all_climatology\n",
        "\n",
        "model_climatology = calculate_monthly_climatology_from_memory(extracted_data)\n",
        "print(f\"\\nâ¡ï¸ Ready for Part 3: Station Data Processing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3_header"
      },
      "source": [
        "# ğŸŒ¡ï¸ Part 3: Station Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process_station_data"
      },
      "outputs": [],
      "source": [
        "def process_station_data():\n",
        "    print(f\"ğŸŒ¡ï¸ PROCESSING STATION DATA\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    station_climatology = []\n",
        "    target_stations = ['AL0019', 'AL0035', 'AL0059']\n",
        "    \n",
        "    for station_id in target_stations:\n",
        "        station_file = f\"input_data/stations_data/{station_id}.xlsx\"\n",
        "        \n",
        "        if not os.path.exists(station_file):\n",
        "            print(f\"âŒ Station file not found: {station_id}.xlsx\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"ğŸ”„ Processing station: {station_id}\")\n",
        "        \n",
        "        try:\n",
        "            df = pd.read_excel(station_file)\n",
        "            \n",
        "            if 'Date' not in df.columns or 'Corrected Tmax' not in df.columns:\n",
        "                print(f\"âŒ Missing required columns in {station_id}\")\n",
        "                continue\n",
        "            \n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df = df[(df['Date'].dt.year >= 1990) & (df['Date'].dt.year <= 2014)]\n",
        "            df['Temperature'] = pd.to_numeric(df['Corrected Tmax'], errors='coerce')\n",
        "            df = df[(df['Temperature'] >= -20) & (df['Temperature'] <= 60)]\n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            \n",
        "            monthly_clim = df.groupby('Month')['Temperature'].agg([\n",
        "                ('Mean_Temp', 'mean'),\n",
        "                ('Min_Temp', 'min'),\n",
        "                ('Max_Temp', 'max'),\n",
        "                ('Std_Temp', 'std'),\n",
        "                ('Count', 'count')\n",
        "            ]).round(2)\n",
        "            \n",
        "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "            monthly_clim['Month_Name'] = month_names\n",
        "            monthly_clim['Station'] = station_id\n",
        "            monthly_clim['Station_Name'] = stations[station_id]['name']\n",
        "            monthly_clim = monthly_clim.reset_index()\n",
        "            \n",
        "            station_climatology.append(monthly_clim)\n",
        "            \n",
        "            valid_days = df['Temperature'].notna().sum()\n",
        "            total_days = len(df)\n",
        "            completeness = (valid_days / total_days) * 100\n",
        "            \n",
        "            print(f\"  âœ… {station_id}: {completeness:.1f}% data completeness\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ Error processing {station_id}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if station_climatology:\n",
        "        combined_station_clim = pd.concat(station_climatology, ignore_index=True)\n",
        "        print(f\"\\nâœ… Part 3 Complete: Station climatology for {len(station_climatology)} stations\")\n",
        "        return combined_station_clim\n",
        "    else:\n",
        "        print(\"âŒ No station data processed\")\n",
        "        return None\n",
        "\n",
        "station_climatology = process_station_data()\n",
        "print(f\"\\nâ¡ï¸ Ready for Part 4: Model Validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part4_header"
      },
      "source": [
        "# ğŸ“ Part 4: Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_functions"
      },
      "outputs": [],
      "source": [
        "def calculate_validation_metrics(model_temps, obs_temps):\n",
        "    valid_mask = ~(np.isnan(model_temps) | np.isnan(obs_temps))\n",
        "    model_valid = model_temps[valid_mask]\n",
        "    obs_valid = obs_temps[valid_mask]\n",
        "    \n",
        "    if len(model_valid) < 3:\n",
        "        return None\n",
        "    \n",
        "    metrics = {}\n",
        "    \n",
        "    # 1. Root Mean Square Error (RMSE)\n",
        "    metrics['RMSE'] = np.sqrt(np.mean((model_valid - obs_valid) ** 2))\n",
        "    \n",
        "    # 2. Correlation coefficient (R)\n",
        "    metrics['R'] = np.corrcoef(model_valid, obs_valid)[0, 1]\n",
        "    \n",
        "    # 3. Nash-Sutcliffe Efficiency (NSE)\n",
        "    mean_obs = np.mean(obs_valid)\n",
        "    metrics['NSE'] = 1 - (np.sum((model_valid - obs_valid) ** 2) / \n",
        "                         np.sum((obs_valid - mean_obs) ** 2))\n",
        "    \n",
        "    # 4. Percent Bias (PBIAS)\n",
        "    metrics['PBIAS'] = 100 * (np.mean(model_valid - obs_valid) / np.mean(obs_valid))\n",
        "    \n",
        "    # 5. Mean Absolute Error (MAE)\n",
        "    metrics['MAE'] = np.mean(np.abs(model_valid - obs_valid))\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "def perform_validation(model_clim, station_clim):\n",
        "    print(f\"ğŸ“ PERFORMING MODEL VALIDATION\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    if model_clim is None or station_clim is None:\n",
        "        print(\"âŒ Missing climatology data for validation\")\n",
        "        return None, None\n",
        "    \n",
        "    validation_results = []\n",
        "    models = model_clim['Model'].unique()\n",
        "    station_ids = station_clim['Station'].unique()\n",
        "    \n",
        "    for model in models:\n",
        "        for station_id in station_ids:\n",
        "            \n",
        "            print(f\"  ğŸ”„ Validating {model} at {station_id}\")\n",
        "            \n",
        "            model_data = model_clim[(model_clim['Model'] == model) & \n",
        "                                  (model_clim['Station'] == station_id)]\n",
        "            \n",
        "            station_data = station_clim[station_clim['Station'] == station_id]\n",
        "            \n",
        "            if model_data.empty or station_data.empty:\n",
        "                print(f\"    âŒ No data available\")\n",
        "                continue\n",
        "            \n",
        "            model_temps = model_data['Mean_Temp'].values\n",
        "            obs_temps = station_data['Mean_Temp'].values\n",
        "            \n",
        "            metrics = calculate_validation_metrics(model_temps, obs_temps)\n",
        "            \n",
        "            if metrics is None:\n",
        "                print(f\"    âŒ Insufficient data for validation\")\n",
        "                continue\n",
        "            \n",
        "            result = {\n",
        "                'Model': model,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': stations[station_id]['name'],\n",
        "                **metrics\n",
        "            }\n",
        "            validation_results.append(result)\n",
        "            \n",
        "            print(f\"    âœ… R={metrics['R']:.3f}, RMSE={metrics['RMSE']:.2f}Â°C, NSE={metrics['NSE']:.3f}\")\n",
        "    \n",
        "    if not validation_results:\n",
        "        print(\"âŒ No validation results generated\")\n",
        "        return None, None\n",
        "    \n",
        "    results_df = pd.DataFrame(validation_results)\n",
        "    \n",
        "    # Calculate model ranking\n",
        "    model_ranking = results_df.groupby('Model').agg({\n",
        "        'RMSE': 'mean',\n",
        "        'R': 'mean',\n",
        "        'NSE': 'mean', \n",
        "        'PBIAS': lambda x: np.mean(np.abs(x)),\n",
        "        'MAE': 'mean'\n",
        "    }).round(3)\n",
        "    \n",
        "    model_ranking['RMSE_rank'] = model_ranking['RMSE'].rank(ascending=True)\n",
        "    model_ranking['R_rank'] = model_ranking['R'].rank(ascending=False)\n",
        "    model_ranking['NSE_rank'] = model_ranking['NSE'].rank(ascending=False)\n",
        "    model_ranking['PBIAS_rank'] = model_ranking['PBIAS'].rank(ascending=True)\n",
        "    model_ranking['MAE_rank'] = model_ranking['MAE'].rank(ascending=True)\n",
        "    \n",
        "    rank_cols = ['RMSE_rank', 'R_rank', 'NSE_rank', 'PBIAS_rank', 'MAE_rank']\n",
        "    model_ranking['Average_Rank'] = model_ranking[rank_cols].mean(axis=1)\n",
        "    model_ranking = model_ranking.sort_values('Average_Rank')\n",
        "    \n",
        "    print(f\"\\nâœ… Part 4 Complete: {len(results_df)} validations performed\")\n",
        "    return results_df, model_ranking\n",
        "\n",
        "validation_results, model_ranking = perform_validation(model_climatology, station_climatology)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "final_results"
      },
      "source": [
        "# ğŸ¯ Workshop Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_final_results"
      },
      "outputs": [],
      "source": [
        "print(\"ğŸ¯ WORKSHOP RESULTS SUMMARY\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if validation_results is not None and model_ranking is not None:\n",
        "    print(f\"âœ… Validation completed: {len(validation_results)} model-station combinations\")\n",
        "    print(f\"âœ… Models evaluated: {len(validation_results['Model'].unique())}\")\n",
        "    print(
