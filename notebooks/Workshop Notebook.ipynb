{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workshop_header"
      },
      "source": [
        "# ğŸŒ¡ï¸ Climate Model Validation Workshop\n",
        "\n",
        "## Complete End-to-End Analysis\n",
        "**Study Area:** AMMAN ZARQA Basin, Jordan  \n",
        "**Models:** 6 RICCAR Climate Models (SSP4.5)  \n",
        "**Stations:** AL0019, AL0035, AL0059  \n",
        "**Period:** 1990-2014\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Workshop Overview\n",
        "\n",
        "This notebook contains the complete climate model validation workflow:\n",
        "\n",
        "### **Part 1: Station Data Extraction** ğŸ“\n",
        "- Download climate model NetCDF files\n",
        "- Extract temperature data at station locations\n",
        "- Assess spatial resolution and data quality\n",
        "\n",
        "### **Part 2: Monthly Climatology** ğŸ“Š\n",
        "- Convert daily data to monthly climatology\n",
        "- Calculate seasonal temperature patterns\n",
        "- Visualize model seasonal cycles\n",
        "\n",
        "### **Part 3: Station Data Processing** ğŸŒ¡ï¸\n",
        "- Load observed temperature data\n",
        "- Process station climatology\n",
        "- Prepare observational reference\n",
        "\n",
        "### **Part 4: Model Validation** ğŸ“\n",
        "- Calculate 5 validation metrics (RMSE, R, NSE, PBIAS, MAE)\n",
        "- Compare models against observations\n",
        "- Rank model performance\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“š Learning Objectives\n",
        "By the end of this workshop, you will:\n",
        "- âœ… Understand climate model validation workflow\n",
        "- âœ… Extract and process climate data using Python\n",
        "- âœ… Calculate validation metrics and interpret results\n",
        "- âœ… Create publication-quality visualizations\n",
        "- âœ… Make informed decisions about model selection\n",
        "\n",
        "---\n",
        "\n",
        "## â±ï¸ Estimated Time: 45-60 minutes\n",
        "\n",
        "**Ready to start? Let's validate some climate models!** ğŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "# âš™ï¸ Workshop Setup: Install Packages and Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install xarray netcdf4 requests tqdm seaborn -q\n",
        "\n",
        "print(\"âœ… Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_libraries"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "print(\"ğŸ“š Libraries imported successfully!\")\n",
        "print(f\"ğŸ“ Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_data"
      },
      "outputs": [],
      "source": [
        "def download_workshop_data():\n",
        "    \"\"\"Download all required files from GitHub repository\"\"\"\n",
        "    \n",
        "    print(\"ğŸ¯ DOWNLOADING WORKSHOP DATA\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # GitHub repository base URL\n",
        "    base_url = \"https://raw.githubusercontent.com/MoawiahHussien/climate-model-validation-workshop/main/\"\n",
        "    \n",
        "    # Create directories\n",
        "    os.makedirs(\"input_data/models_netcdf\", exist_ok=True)\n",
        "    os.makedirs(\"input_data/stations_data\", exist_ok=True)\n",
        "    os.makedirs(\"workshop_output\", exist_ok=True)\n",
        "    \n",
        "    # NetCDF files to download\n",
        "    nc_files = [\n",
        "        \"arcgis_merged_Tmax_CMCC-CM2-SR5.nc\",\n",
        "        \"arcgis_merged_Tmax_CNRM-ESM2-1.nc\", \n",
        "        \"arcgis_merged_Tmax_EC-Earth3-Veg.nc\",\n",
        "        \"arcgis_merged_Tmax_IPSL-CM6A-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_MPI-ESM1-2-LR.nc\",\n",
        "        \"arcgis_merged_Tmax_NorESM2-MM.nc\"\n",
        "    ]\n",
        "    \n",
        "    # Station files to download\n",
        "    station_files = [\"AL0019.xlsx\", \"AL0035.xlsx\", \"AL0059.xlsx\"]\n",
        "    \n",
        "    # Download NetCDF files\n",
        "    print(\"ğŸ“¥ Downloading climate model files...\")\n",
        "    for nc_file in nc_files:\n",
        "        file_url = base_url + \"Input%20Files/Models.Nc.ArcGIS.Compatible/\" + nc_file\n",
        "        local_path = f\"input_data/models_netcdf/{nc_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"âœ… Using cached: {nc_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"ğŸ“¥ Downloading: {nc_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   âœ… Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Failed: {e}\")\n",
        "    \n",
        "    # Download station files\n",
        "    print(\"\\nğŸ“¥ Downloading station files...\")\n",
        "    for station_file in station_files:\n",
        "        file_url = base_url + \"Input%20Files/Stations.Daily/\" + station_file\n",
        "        local_path = f\"input_data/stations_data/{station_file}\"\n",
        "        \n",
        "        if os.path.exists(local_path):\n",
        "            print(f\"âœ… Using cached: {station_file}\")\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(f\"ğŸ“¥ Downloading: {station_file}\")\n",
        "            urllib.request.urlretrieve(file_url, local_path)\n",
        "            file_size = os.path.getsize(local_path) / (1024*1024)\n",
        "            print(f\"   âœ… Complete: {file_size:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Failed: {e}\")\n",
        "    \n",
        "    print(f\"\\nğŸ‰ Data download complete!\")\n",
        "\n",
        "# Download the data\n",
        "download_workshop_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "define_constants"
      },
      "outputs": [],
      "source": [
        "# Define workshop configuration\n",
        "stations = {\n",
        "    'AL0019': {'lat': 31.95, 'lon': 35.93, 'name': 'Amman Airport'},\n",
        "    'AL0035': {'lat': 32.01, 'lon': 35.85, 'name': 'Zarqa Station'}, \n",
        "    'AL0059': {'lat': 31.97, 'lon': 36.12, 'name': 'Russeifa Station'}\n",
        "}\n",
        "\n",
        "model_files = {\n",
        "    'CMCC': 'arcgis_merged_Tmax_CMCC-CM2-SR5.nc',\n",
        "    'CNRM': 'arcgis_merged_Tmax_CNRM-ESM2-1.nc',\n",
        "    'EC-Earth3': 'arcgis_merged_Tmax_EC-Earth3-Veg.nc',\n",
        "    'IPSL': 'arcgis_merged_Tmax_IPSL-CM6A-LR.nc',\n",
        "    'MPI': 'arcgis_merged_Tmax_MPI-ESM1-2-LR.nc',\n",
        "    'NorESM2': 'arcgis_merged_Tmax_NorESM2-MM.nc'\n",
        "}\n",
        "\n",
        "model_colors = {\n",
        "    'CMCC': '#1f77b4', 'CNRM': '#ff7f0e', 'EC-Earth3': '#2ca02c',\n",
        "    'IPSL': '#d62728', 'MPI': '#9467bd', 'NorESM2': '#8c564b'\n",
        "}\n",
        "\n",
        "print(f\"ğŸ¯ WORKSHOP CONFIGURATION\")\n",
        "print(f\"ğŸ“ Target Stations: {len(stations)}\")\n",
        "print(f\"ğŸŒ¡ï¸ Climate Models: {len(model_files)}\")\n",
        "\n",
        "for station_id, info in stations.items():\n",
        "    print(f\"  {station_id}: {info['name']} ({info['lat']:.2f}Â°N, {info['lon']:.2f}Â°E)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1_header"
      },
      "source": [
        "# ğŸ“ Part 1: Station Data Extraction from Climate Models\n",
        "\n",
        "Extract temperature data at our 3 weather station locations from 6 climate models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_station_data"
      },
      "outputs": [],
      "source": [
        "def extract_station_data():\n",
        "    \"\"\"Extract temperature data at station locations from all models\"\"\"\n",
        "    \n",
        "    print(f\"ğŸ“ EXTRACTING DATA AT STATION LOCATIONS\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    # Storage for results\n",
        "    model_station_data = {}\n",
        "    extraction_log = []\n",
        "    \n",
        "    # Process each model\n",
        "    for model_name, filename in model_files.items():\n",
        "        print(f\"\\nğŸ”„ Processing: {model_name}\")\n",
        "        \n",
        "        file_path = f\"input_data/models_netcdf/{filename}\"\n",
        "        \n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"    âŒ File not found: {filename}\")\n",
        "            continue\n",
        "        \n",
        "        # Open NetCDF file\n",
        "        ds = xr.open_dataset(file_path)\n",
        "        model_station_data[model_name] = {}\n",
        "        \n",
        "        # Extract data for each station\n",
        "        for station_id, station_info in stations.items():\n",
        "            # Extract data at station location\n",
        "            station_data = ds.tasmaxAdjust.sel(\n",
        "                lat=station_info['lat'], \n",
        "                lon=station_info['lon'], \n",
        "                method='nearest'\n",
        "            )\n",
        "            \n",
        "            # Get grid coordinates\n",
        "            grid_lat = float(station_data.lat.values)\n",
        "            grid_lon = float(station_data.lon.values)\n",
        "            distance_km = np.sqrt((grid_lat - station_info['lat'])**2 + \n",
        "                                (grid_lon - station_info['lon'])**2) * 111\n",
        "            \n",
        "            # Store extracted data\n",
        "            model_station_data[model_name][station_id] = station_data.values\n",
        "            \n",
        "            # Log extraction info\n",
        "            extraction_log.append({\n",
        "                'Model': model_name,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': station_info['name'],\n",
        "                'Distance_km': round(distance_km, 2),\n",
        "                'Days_Extracted': len(station_data),\n",
        "                'Valid_Days': int(np.sum(~np.isnan(station_data.values)))\n",
        "            })\n",
        "            \n",
        "            print(f\"    âœ… {station_id}: {len(station_data)} days, distance: {distance_km:.2f} km\")\n",
        "        \n",
        "        ds.close()\n",
        "    \n",
        "    print(f\"\\nâœ… Part 1 Complete: {len(extraction_log)} extractions\")\n",
        "    return model_station_data, pd.DataFrame(extraction_log)\n",
        "\n",
        "# Execute Part 1\n",
        "extracted_data, extraction_summary = extract_station_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "part1_visualization"
      },
      "outputs": [],
      "source": [
        "# Create Part 1 visualization\n",
        "def create_part1_visualization():\n",
        "    \"\"\"Create visualization for Part 1 results\"\"\"\n",
        "    \n",
        "    print(\"ğŸ“Š CREATING PART 1 VISUALIZATION\")\n",
        "    print(\"-\" * 35)\n",
        "    \n",
        "    # Create temperature summary for visualization\n",
        "    summary_data = []\n",
        "    for model_name in extracted_data.keys():\n",
        "        for station_id in extracted_data[model_name].keys():\n",
        "            temp_data = extracted_data[model_name][station_id]\n",
        "            summary_data.append({\n",
        "                'Model': model_name,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': stations[station_id]['name'],\n",
        "                'Mean_Temp': round(np.nanmean(temp_data), 2),\n",
        "                'Min_Temp': round(np.nanmin(temp_data), 2),\n",
        "                'Max_Temp': round(np.nanmax(temp_data), 2)\n",
        "            })\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
        "\n",
        "    # 1. Distance to grid points\n",
        "    ax1 = axes[0]\n",
        "    extraction_summary.boxplot(column='Distance_km', by='Station', ax=ax1)\n",
        "    ax1.set_title('Distance to Nearest Grid Point by Station\\n(Spatial Resolution Check)', \n",
        "                  fontsize=11, fontweight='bold', pad=15)\n",
        "    ax1.set_ylabel('Distance (km)', fontsize=10)\n",
        "    ax1.set_xlabel('Station ID', fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Temperature ranges by model\n",
        "    ax2 = axes[1]\n",
        "    models = list(model_colors.keys())\n",
        "    model_temps = [summary_df[summary_df['Model'] == model]['Mean_Temp'].values for model in models]\n",
        "\n",
        "    bp = ax2.boxplot(model_temps, labels=models, patch_artist=True, widths=0.6)\n",
        "    for patch, model in zip(bp['boxes'], models):\n",
        "        patch.set_facecolor(model_colors[model])\n",
        "        patch.set_alpha(0.7)\n",
        "\n",
        "    ax2.set_title('Mean Temperature by Model\\n1990-2014 Daily Average', \n",
        "                  fontsize=11, fontweight='bold', pad=15)\n",
        "    ax2.set_ylabel('Temperature (Â°C)', fontsize=10)\n",
        "    ax2.set_xlabel('Climate Model', fontsize=10)\n",
        "    ax2.tick_params(axis='x', rotation=45, labelsize=9)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Temperature by station (with model colors)\n",
        "    ax3 = axes[2]\n",
        "    stations_order = ['AL0019', 'AL0035', 'AL0059']\n",
        "\n",
        "    for model in models:\n",
        "        model_data = summary_df[summary_df['Model'] == model]\n",
        "        temps = []\n",
        "        x_positions = []\n",
        "        \n",
        "        for i, station_id in enumerate(stations_order):\n",
        "            station_temp = model_data[model_data['Station'] == station_id]['Mean_Temp']\n",
        "            if not station_temp.empty:\n",
        "                temps.append(station_temp.values[0])\n",
        "                x_positions.append(i)\n",
        "        \n",
        "        if temps:\n",
        "            ax3.scatter(x_positions, temps, label=model, color=model_colors[model], \n",
        "                       alpha=0.8, s=80, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "    ax3.set_title('Mean Temperature by Station\\n1990-2014 Daily Average (All Models)', \n",
        "                  fontsize=11, fontweight='bold', pad=15)\n",
        "    ax3.set_ylabel('Temperature (Â°C)', fontsize=10)\n",
        "    ax3.set_xlabel('Station Location', fontsize=10)\n",
        "    ax3.set_xticks(range(len(stations_order)))\n",
        "    ax3.set_xticklabels([f\"{sid}\\n({stations[sid]['name']})\" for sid in stations_order], fontsize=8)\n",
        "    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    fig.suptitle('Part 1: Climate Model Data Extraction Results\\nPeriod: 1990-2014 (25 years, daily data)', \n",
        "                 fontsize=13, fontweight='bold', y=0.95)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.82, right=0.85, bottom=0.15, wspace=0.35)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"âœ… Part 1 visualization complete!\")\n",
        "\n",
        "# Create the visualization\n",
        "create_part1_visualization()\n",
        "\n",
        "# Display summary\n",
        "print(\"\\nğŸ¯ PART 1 SUMMARY\")\n",
        "print(\"=\" * 20)\n",
        "print(f\"âœ… Models processed: {len(extracted_data)}\")\n",
        "print(f\"âœ… Stations extracted: {len(stations)}\")\n",
        "print(f\"âœ… Total extractions: {len(extraction_summary)}\")\n",
        "\n",
        "avg_distance = extraction_summary['Distance_km'].mean()\n",
        "avg_completeness = ((extraction_summary['Valid_Days'].sum() / extraction_summary['Days_Extracted'].sum()) * 100)\n",
        "\n",
        "print(f\"\\nğŸ“Š Data Quality:\")\n",
        "print(f\"  Average distance to grid: {avg_distance:.2f} km\")\n",
        "print(f\"  Average data completeness: {avg_completeness:.1f}%\")\n",
        "\n",
        "print(f\"\\nâ¡ï¸ Ready for Part 2: Monthly Climatology Calculation\")\n",
        "print(f\"ğŸ”— Data stored in memory for seamless workflow\")"
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2_header"
      },
      "source": [
        "# ğŸ“Š Part 2: Monthly Climatology Calculation\n",
        "\n",
        "Convert the daily temperature data to monthly climatology to see seasonal patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "calculate_climatology"
      },
      "outputs": [],
      "source": [
        "def calculate_monthly_climatology_from_memory(extracted_data):\n",
        "    \"\"\"Calculate monthly climatology from extracted data in memory\"\"\"\n",
        "    \n",
        "    print(f\"ğŸ“Š CALCULATING MONTHLY CLIMATOLOGY\")\n",
        "    print(\"-\" * 35)\n",
        "    \n",
        "    climatology_data = []\n",
        "    \n",
        "    # Process each model-station combination\n",
        "    for model_name in extracted_data.keys():\n",
        "        for station_id in extracted_data[model_name].keys():\n",
        "            \n",
        "            print(f\"  ğŸ”„ Processing {model_name} - {station_id}\")\n",
        "            \n",
        "            # Create time index and DataFrame\n",
        "            temp_data = extracted_data[model_name][station_id]\n",
        "            time_index = pd.date_range('1990-01-01', periods=len(temp_data), freq='D')\n",
        "            \n",
        "            df = pd.DataFrame({\n",
        "                'Date': time_index,\n",
        "                'Temperature_C': temp_data\n",
        "            })\n",
        "            \n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            \n",
        "            # Calculate monthly climatology\n",
        "            monthly_clim = df.groupby('Month')['Temperature_C'].agg([\n",
        "                ('Mean_Temp', 'mean'),\n",
        "                ('Min_Temp', 'min'),\n",
        "                ('Max_Temp', 'max'),\n",
        "                ('Std_Temp', 'std')\n",
        "            ]).round(2)\n",
        "            \n",
        "            # Add month names and identification\n",
        "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "            monthly_clim['Month_Name'] = month_names\n",
        "            monthly_clim['Model'] = model_name\n",
        "            monthly_clim['Station'] = station_id\n",
        "            monthly_clim['Station_Name'] = stations[station_id]['name']\n",
        "            monthly_clim = monthly_clim.reset_index()\n",
        "            \n",
        "            climatology_data.append(monthly_clim)\n",
        "    \n",
        "    # Combine all climatology data\n",
        "    all_climatology = pd.concat(climatology_data, ignore_index=True)\n",
        "    \n",
        "    print(f\"\\nâœ… Part 2 Complete: Monthly climatology for {len(climatology_data)} model-station combinations\")\n",
        "    return all_climatology\n",
        "\n",
        "# Execute Part 2\n",
        "model_climatology = calculate_monthly_climatology_from_memory(extracted_data)\n",
        "\n",
        "if model_climatology is not None:\n",
        "    print(f\"\\nğŸ“Š Climatology Summary:\")\n",
        "    print(f\"  Total records: {len(model_climatology)}\")\n",
        "    print(f\"  Models: {model_climatology['Model'].nunique()}\")\n",
        "    print(f\"  Stations: {model_climatology['Station'].nunique()}\")\n",
        "    print(f\"  Temperature range: {model_climatology['Mean_Temp'].min():.1f}Â°C to {model_climatology['Mean_Temp'].max():.1f}Â°C\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "climatology_visualization"
      },
      "outputs": [],
      "source": [
        "def create_climatology_visualization(climatology_df):\n",
        "    \"\"\"Create comprehensive climatology visualization\"\"\"\n",
        "    \n",
        "    print(f\"ğŸ“ˆ CREATING CLIMATOLOGY VISUALIZATION\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Create subplots for each station\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    stations_order = ['AL0019', 'AL0035', 'AL0059']\n",
        "    \n",
        "    for i, station_id in enumerate(stations_order):\n",
        "        ax = axes[i]\n",
        "        \n",
        "        # Plot each model for this station\n",
        "        for model in climatology_df['Model'].unique():\n",
        "            data = climatology_df[(climatology_df['Model'] == model) & \n",
        "                                (climatology_df['Station'] == station_id)]\n",
        "            \n",
        "            if not data.empty:\n",
        "                months = data['Month'].values\n",
        "                temps = data['Mean_Temp'].values\n",
        "                \n",
        "                ax.plot(months, temps, 'o-', color=model_colors[model], \n",
        "                       label=model, linewidth=2, markersize=6, alpha=0.8)\n",
        "        \n",
        "        # Formatting\n",
        "        ax.set_title(f'{station_id}\\n({stations[station_id][\"name\"]})', fontsize=12, fontweight='bold')\n",
        "        ax.set_xlabel('Month', fontsize=10)\n",
        "        ax.set_ylabel('Temperature (Â°C)', fontsize=10)\n",
        "        ax.set_xticks(range(1, 13))\n",
        "        ax.set_xticklabels(['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D'])\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add legend only to the last subplot\n",
        "        if i == 2:\n",
        "            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "    \n",
        "    # Main title\n",
        "    fig.suptitle('Part 2: Monthly Temperature Climatology by Station\\n1990-2014 Average (All Models)', \n",
        "                 fontsize=14, fontweight='bold', y=0.98)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.85, right=0.85)\n",
        "    \n",
        "    plt.show()\n",
        "    print(f\"âœ… Climatology visualization complete!\")\n",
        "\n",
        "# Create the visualization\n",
        "if model_climatology is not None:\n",
        "    create_climatology_visualization(model_climatology)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seasonal_analysis"
      },
      "outputs": [],
      "source": [
        "def calculate_seasonal_summary(climatology_df):\n",
        "    \"\"\"Calculate seasonal temperature summary\"\"\"\n",
        "    \n",
        "    print(f\"ğŸŒ¡ï¸ CALCULATING SEASONAL SUMMARY\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # Define seasons\n",
        "    seasons = {\n",
        "        'Winter': [12, 1, 2],\n",
        "        'Spring': [3, 4, 5],\n",
        "        'Summer': [6, 7, 8],\n",
        "        'Autumn': [9, 10, 11]\n",
        "    }\n",
        "    \n",
        "    seasonal_data = []\n",
        "    \n",
        "    for model in climatology_df['Model'].unique():\n",
        "        for station in climatology_df['Station'].unique():\n",
        "            data = climatology_df[(climatology_df['Model'] == model) & \n",
        "                                (climatology_df['Station'] == station)]\n",
        "            \n",
        "            if not data.empty:\n",
        "                row = {\n",
        "                    'Model': model,\n",
        "                    'Station': station,\n",
        "                    'Station_Name': stations[station]['name']\n",
        "                }\n",
        "                \n",
        "                for season, months in seasons.items():\n",
        "                    season_temps = data[data['Month'].isin(months)]['Mean_Temp']\n",
        "                    row[f'{season}_Temp'] = round(season_temps.mean(), 2)\n",
        "                \n",
        "                # Annual average\n",
        "                row['Annual_Temp'] = round(data['Mean_Temp'].mean(), 2)\n",
        "                \n",
        "                seasonal_data.append(row)\n",
        "    \n",
        "    seasonal_df = pd.DataFrame(seasonal_data)\n",
        "    \n",
        "    # Display summary statistics\n",
        "    print(f\"\\nğŸŒ¡ï¸ Seasonal Temperature Ranges:\")\n",
        "    for season in ['Winter', 'Spring', 'Summer', 'Autumn']:\n",
        "        col_name = f'{season}_Temp'\n",
        "        min_temp = seasonal_df[col_name].min()\n",
        "        max_temp = seasonal_df[col_name].max()\n",
        "        print(f\"  {season}: {min_temp:.1f}Â°C to {max_temp:.1f}Â°C\")\n",
        "    \n",
        "    return seasonal_df\n",
        "\n",
        "# Calculate seasonal summary\n",
        "if model_climatology is not None:\n",
        "    seasonal_summary = calculate_seasonal_summary(model_climatology)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "part2_data_preview"
      },
      "outputs": [],
      "source": [
        "# Display sample climatology data and analysis\n",
        "if model_climatology is not None:\n",
        "    print(\"ğŸ“‹ PART 2 DATA PREVIEW\")\n",
        "    print(\"=\" * 25)\n",
        "    \n",
        "    # Show first few rows\n",
        "    print(\"\\nğŸ” Sample Climatology Data (First 10 records):\")\n",
        "    display(model_climatology[['Model', 'Station', 'Month_Name', 'Mean_Temp', 'Min_Temp', 'Max_Temp']].head(10))\n",
        "    \n",
        "    # Show summary by model\n",
        "    print(\"\\nğŸ“Š Average Temperature by Model (across all stations and months):\")\n",
        "    model_avg = model_climatology.groupby('Model')['Mean_Temp'].mean().round(2)\n",
        "    for model, temp in model_avg.items():\n",
        "        print(f\"  {model}: {temp:.2f}Â°C\")\n",
        "    \n",
        "    # Show summary by station\n",
        "    print(\"\\nğŸ“ Average Temperature by Station (across all models and months):\")\n",
        "    station_avg = model_climatology.groupby(['Station', 'Station_Name'])['Mean_Temp'].mean().round(2)\n",
        "    for (station_id, station_name), temp in station_avg.items():\n",
        "        print(f\"  {station_id} ({station_name}): {temp:.2f}Â°C\")\n",
        "    \n",
        "    # Monthly temperature range\n",
        "    print(f\"\\nğŸŒ¡ï¸ Monthly Temperature Patterns:\")\n",
        "    monthly_avg = model_climatology.groupby('Month_Name')['Mean_Temp'].agg(['min', 'max', 'mean']).round(1)\n",
        "    month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "    monthly_avg = monthly_avg.reindex(month_order)\n",
        "    \n",
        "    for month, row in monthly_avg.iterrows():\n",
        "        print(f\"  {month}: {row['min']:.1f}Â°C to {row['max']:.1f}Â°C (avg: {row['mean']:.1f}Â°C)\")\n",
        "else:\n",
        "    print(\"âŒ No climatology data available for preview\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "part2_summary"
      },
      "outputs": [],
      "source": [
        "# Part 2 Summary\n",
        "if model_climatology is not None:\n",
        "    print(\"\\nğŸ¯ PART 2 SUMMARY\")\n",
        "    print(\"=\" * 20)\n",
        "    print(f\"âœ… Monthly climatology calculated for {len(model_climatology['Model'].unique())} models\")\n",
        "    print(f\"âœ… {len(model_climatology['Station'].unique())} stations processed\")\n",
        "    print(f\"âœ… 12 months Ã— {len(model_climatology['Model'].unique())} models Ã— {len(model_climatology['Station'].unique())} stations = {len(model_climatology)} records\")\n",
        "    \n",
        "    print(f\"\\nğŸ“Š Temperature Ranges:\")\n",
        "    print(f\"  Coldest month average: {model_climatology['Mean_Temp'].min():.1f}Â°C\")\n",
        "    print(f\"  Warmest month average: {model_climatology['Mean_Temp'].max():.1f}Â°C\")\n",
        "    print(f\"  Annual temperature range: {model_climatology['Mean_Temp'].max() - model_climatology['Mean_Temp'].min():.1f}Â°C\")\n",
        "    \n",
        "    print(f\"\\nğŸ“ Key Learning Points:\")\n",
        "    print(f\"  â€¢ Monthly climatology reveals seasonal temperature patterns\")\n",
        "    print(f\"  â€¢ All models show similar seasonal cycles (summer peak, winter minimum)\")\n",
        "    print(f\"  â€¢ Small but consistent differences between models\")\n",
        "    print(f\"  â€¢ Spatial temperature gradient maintained across seasons\")\n",
        "    print(f\"  â€¢ Data ready for validation against observations\")\n",
        "    \n",
        "    print(f\"\\nâ¡ï¸ Ready for Part 3: Station Data Processing\")\n",
        "    print(f\"ğŸ”— Model climatology stored in memory for validation\")\n",
        "else:\n",
        "    print(\"âŒ Part 2 could not be completed. Please check Part 1 results.\")"
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3_header"
      },
      "source": [
        "# ğŸŒ¡ï¸ Part 3: Station Data Processing\n",
        "\n",
        "Process observed temperature data from weather stations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process_station_data"
      },
      "outputs": [],
      "source": [
        "def process_station_data():\n",
        "    \"\"\"Process observed station data for validation\"\"\"\n",
        "    \n",
        "    print(f\"ğŸŒ¡ï¸ PROCESSING STATION DATA\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    station_climatology = []\n",
        "    target_stations = ['AL0019', 'AL0035', 'AL0059']\n",
        "    \n",
        "    for station_id in target_stations:\n",
        "        station_file = f\"input_data/stations_data/{station_id}.xlsx\"\n",
        "        \n",
        "        if not os.path.exists(station_file):\n",
        "            print(f\"âŒ Station file not found: {station_id}.xlsx\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"ğŸ”„ Processing station: {station_id}\")\n",
        "        \n",
        "        try:\n",
        "            # Read and process station data\n",
        "            df = pd.read_excel(station_file)\n",
        "            \n",
        "            if 'Date' not in df.columns or 'Corrected Tmax' not in df.columns:\n",
        "                print(f\"âŒ Missing required columns in {station_id}\")\n",
        "                continue\n",
        "            \n",
        "            # Filter for study period and clean data\n",
        "            df['Date'] = pd.to_datetime(df['Date'])\n",
        "            df = df[(df['Date'].dt.year >= 1990) & (df['Date'].dt.year <= 2014)]\n",
        "            df['Temperature'] = pd.to_numeric(df['Corrected Tmax'], errors='coerce')\n",
        "            df = df[(df['Temperature'] >= -20) & (df['Temperature'] <= 60)]\n",
        "            df['Month'] = df['Date'].dt.month\n",
        "            \n",
        "            # Calculate monthly climatology\n",
        "            monthly_clim = df.groupby('Month')['Temperature'].agg([\n",
        "                ('Mean_Temp', 'mean'),\n",
        "                ('Min_Temp', 'min'),\n",
        "                ('Max_Temp', 'max'),\n",
        "                ('Std_Temp', 'std'),\n",
        "                ('Count', 'count')\n",
        "            ]).round(2)\n",
        "            \n",
        "            # Add identification\n",
        "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "            monthly_clim['Month_Name'] = month_names\n",
        "            monthly_clim['Station'] = station_id\n",
        "            monthly_clim['Station_Name'] = stations[station_id]['name']\n",
        "            monthly_clim = monthly_clim.reset_index()\n",
        "            \n",
        "            station_climatology.append(monthly_clim)\n",
        "            \n",
        "            valid_days = df['Temperature'].notna().sum()\n",
        "            total_days = len(df)\n",
        "            completeness = (valid_days / total_days) * 100\n",
        "            \n",
        "            print(f\"  âœ… {station_id}: {completeness:.1f}% data completeness\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  âŒ Error processing {station_id}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if station_climatology:\n",
        "        combined_station_clim = pd.concat(station_climatology, ignore_index=True)\n",
        "        print(f\"\\nâœ… Part 3 Complete: Station climatology for {len(station_climatology)} stations\")\n",
        "        return combined_station_clim\n",
        "    else:\n",
        "        print(\"âŒ No station data processed\")\n",
        "        return None\n",
        "\n",
        "# Execute Part 3\n",
        "station_climatology = process_station_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "station_visualization"
      },
      "outputs": [],
      "source": [
        "# Create station data visualization\n",
        "if station_climatology is not None:\n",
        "    \n",
        "    print(\"ğŸ“Š CREATING STATION VISUALIZATION\")\n",
        "    \n",
        "    station_colors = {'AL0019': '#1f77b4', 'AL0035': '#ff7f0e', 'AL0059': '#2ca02c'}\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # 1. Monthly climatology\n",
        "    ax1 = axes[0]\n",
        "    for station_id in ['AL0019', 'AL0035', 'AL0059']:\n",
        "        station_clim = station_climatology[station_climatology['Station'] == station_id]\n",
        "        if not station_clim.empty:\n",
        "            months = station_clim['Month'].values\n",
        "            temps = station_clim['Mean_Temp'].values\n",
        "            ax1.plot(months, temps, 'o-', color=station_colors[station_id], \n",
        "                    label=f'{station_id} ({stations[station_id][\"name\"]})', linewidth=2, markersize=6)\n",
        "    \n",
        "    ax1.set_title('Observed Monthly Temperature Climatology\\n1990-2014 Average', fontweight='bold')\n",
        "    ax1.set_xlabel('Month')\n",
        "    ax1.set_ylabel('Temperature (Â°C)')\n",
        "    ax1.set_xticks(range(1, 13))\n",
        "    ax1.set_xticklabels(['J', 'F', 'M', 'A', 'M', 'J', 'J', 'A', 'S', 'O', 'N', 'D'])\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.legend(fontsize=9)\n",
        "    \n",
        "    # 2. Data completeness\n",
        "    ax2 = axes[1]\n",
        "    stations_processed = []\n",
        "    data_completeness = []\n",
        "    \n",
        "    for station_id in ['AL0019', 'AL0035', 'AL0059']:\n",
        "        if station_id in station_climatology['Station'].values:\n",
        "            stations_processed.append(station_id)\n",
        "            # Estimate completeness from count data\n",
        "            station_data = station_climatology[station_climatology['Station'] == station_id]\n",
        "            avg_count = station_data['Count'].mean()\n",
        "            expected_days_per_month = 25 * 365.25 / 12  # 25 years average\n",
        "            completeness = min(100, (avg_count / expected_days_per_month) * 100)\n",
        "            data_completeness.append(completeness)\n",
        "    \n",
        "    bars = ax2.bar(range(len(stations_processed)), data_completeness, \n",
        "                   color=[station_colors[sid] for sid in stations_processed], alpha=0.7, edgecolor='black')\n",
        "    \n",
        "    ax2.set_title('Station Data Quality\\n1990-2014 Period', fontweight='bold')\n",
        "    ax2.set_ylabel('Data Completeness (%)')\n",
        "    ax2.set_xlabel('Station')\n",
        "    ax2.set_xticks(range(len(stations_processed)))\n",
        "    ax2.set_xticklabels(stations_processed)\n",
        "    ax2.set_ylim(0, 105)\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Add percentage labels on bars\n",
        "    for bar, pct in zip(bars, data_completeness):\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                f'{pct:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    fig.suptitle('Part 3: Station Data Processing Results', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"âœ… Station visualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "part3_summary"
      },
      "outputs": [],
      "source": [
        "# Part 3 Summary\n",
        "if station_climatology is not None:\n",
        "    print(\"\\nğŸ¯ PART 3 SUMMARY\")\n",
        "    print(\"=\" * 20)\n",
        "    print(f\"âœ… Stations processed: {len(station_climatology['Station'].unique())}\")\n",
        "    print(f\"âœ… Total monthly records: {len(station_climatology)}\")\n",
        "    print(f\"âœ… Study period: 1990-2014 (25 years)\")\n",
        "    \n",
        "    print(f\"\\nğŸ“Š Station Data Quality:\")\n",
        "    for station_id in station_climatology['Station'].unique():\n",
        "        station_data = station_climatology[station_climatology['Station'] == station_id]\n",
        "        avg_temp = station_data['Mean_Temp'].mean()\n",
        "        print(f\"  {station_id}: avg temp {avg_temp:.1f}Â°C\")\n",
        "    \n",
        "    print(f\"\\nâ¡ï¸ Ready for Part 4: Model Validation\")\n",
        "    print(f\"ğŸ”— Station climatology ready for comparison with models\")\n",
        "else:\n",
        "    print(\"âŒ Part 3 failed - no station data available\")"
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part4_header"
      },
      "source": [
        "# ğŸ“ Part 4: Model Validation\n",
        "\n",
        "Validate climate models against observations using 5 statistical metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_functions"
      },
      "outputs": [],
      "source": [
        "def calculate_validation_metrics(model_temps, obs_temps):\n",
        "    \"\"\"Calculate the 5 validation metrics\"\"\"\n",
        "    \n",
        "    # Remove NaN values\n",
        "    valid_mask = ~(np.isnan(model_temps) | np.isnan(obs_temps))\n",
        "    model_valid = model_temps[valid_mask]\n",
        "    obs_valid = obs_temps[valid_mask]\n",
        "    \n",
        "    if len(model_valid) < 3:\n",
        "        return None\n",
        "    \n",
        "    metrics = {}\n",
        "    \n",
        "    # 1. Root Mean Square Error (RMSE)\n",
        "    metrics['RMSE'] = np.sqrt(np.mean((model_valid - obs_valid) ** 2))\n",
        "    \n",
        "    # 2. Correlation coefficient (R)\n",
        "    metrics['R'] = np.corrcoef(model_valid, obs_valid)[0, 1]\n",
        "    \n",
        "    # 3. Nash-Sutcliffe Efficiency (NSE)\n",
        "    mean_obs = np.mean(obs_valid)\n",
        "    metrics['NSE'] = 1 - (np.sum((model_valid - obs_valid) ** 2) / \n",
        "                         np.sum((obs_valid - mean_obs) ** 2))\n",
        "    \n",
        "    # 4. Percent Bias (PBIAS)\n",
        "    metrics['PBIAS'] = 100 * (np.mean(model_valid - obs_valid) / np.mean(obs_valid))\n",
        "    \n",
        "    # 5. Mean Absolute Error (MAE)\n",
        "    metrics['MAE'] = np.mean(np.abs(model_valid - obs_valid))\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "def perform_validation(model_clim, station_clim):\n",
        "    \"\"\"Perform complete model validation\"\"\"\n",
        "    \n",
        "    print(f\"ğŸ“ PERFORMING MODEL VALIDATION\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    if model_clim is None or station_clim is None:\n",
        "        print(\"âŒ Missing climatology data for validation\")\n",
        "        return None, None\n",
        "    \n",
        "    validation_results = []\n",
        "    models = model_clim['Model'].unique()\n",
        "    station_ids = station_clim['Station'].unique()\n",
        "    \n",
        "    # Process each model-station combination\n",
        "    for model in models:\n",
        "        for station_id in station_ids:\n",
        "            \n",
        "            print(f\"  ğŸ”„ Validating {model} at {station_id}\")\n",
        "            \n",
        "            # Get model data\n",
        "            model_data = model_clim[(model_clim['Model'] == model) & \n",
        "                                  (model_clim['Station'] == station_id)]\n",
        "            \n",
        "            # Get station data\n",
        "            station_data = station_clim[station_clim['Station'] == station_id]\n",
        "            \n",
        "            if model_data.empty or station_data.empty:\n",
        "                print(f\"    âŒ No data available\")\n",
        "                continue\n",
        "            \n",
        "            # Extract monthly temperature arrays\n",
        "            model_temps = model_data['Mean_Temp'].values\n",
        "            obs_temps = station_data['Mean_Temp'].values\n",
        "            \n",
        "            # Calculate metrics\n",
        "            metrics = calculate_validation_metrics(model_temps, obs_temps)\n",
        "            \n",
        "            if metrics is None:\n",
        "                print(f\"    âŒ Insufficient data for validation\")\n",
        "                continue\n",
        "            \n",
        "            # Store results\n",
        "            result = {\n",
        "                'Model': model,\n",
        "                'Station': station_id,\n",
        "                'Station_Name': stations[station_id]['name'],\n",
        "                **metrics\n",
        "            }\n",
        "            validation_results.append(result)\n",
        "            \n",
        "            print(f\"    âœ… R={metrics['R']:.3f}, RMSE={metrics['RMSE']:.2f}Â°C, NSE={metrics['NSE']:.3f}\")\n",
        "    \n",
        "    if not validation_results:\n",
        "        print(\"âŒ No validation results generated\")\n",
        "        return None, None\n",
        "    \n",
        "    results_df = pd.DataFrame(validation_results)\n",
        "    \n",
        "    # Calculate model ranking\n",
        "    model_ranking = results_df.groupby('Model').agg({\n",
        "        'RMSE': 'mean',\n",
        "        'R': 'mean',\n",
        "        'NSE': 'mean', \n",
        "        'PBIAS': lambda x: np.mean(np.abs(x)),\n",
        "        'MAE': 'mean'\n",
        "    }).round(3)\n",
        "    \n",
        "    # Calculate overall rank\n",
        "    model_ranking['RMSE_rank'] = model_ranking['RMSE'].rank(ascending=True)\n",
        "    model_ranking['R_rank'] = model_ranking['R'].rank(ascending=False)\n",
        "    model_ranking['NSE_rank'] = model_ranking['NSE'].rank(ascending=False)\n",
        "    model_ranking['PBIAS_rank'] = model_ranking['PBIAS'].rank(ascending=True)\n",
        "    model_ranking['MAE_rank'] = model_ranking['MAE'].rank(ascending=True)\n",
        "    \n",
        "    rank_cols = ['RMSE_rank', 'R_rank', 'NSE_rank', 'PBIAS_rank', 'MAE_rank']\n",
        "    model_ranking['Average_Rank'] = model_ranking[rank_cols].mean(axis=1)\n",
        "    model_ranking = model_ranking.sort_values('Average_Rank')\n",
        "    \n",
        "    print(f\"\\nâœ… Part 4 Complete: {len(results_df)} validations performed\")\n",
        "    return results_df, model_ranking\n",
        "\n",
        "# Execute Part 4\n",
        "validation_results, model_ranking = perform_validation(model_climatology, station_climatology)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_visualization"
      },
      "outputs": [],
      "source": [
        "# Create comprehensive validation visualization\n",
        "if validation_results is not None and model_ranking is not None:\n",
        "    \n",
        "    print(\"ğŸ“Š CREATING VALIDATION VISUALIZATION\")\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    \n",
        "    # 1. RMSE Heatmap\n",
        "    ax1 = axes[0, 0]\n",
        "    rmse_pivot = validation_results.pivot(index='Station', columns='Model', values='RMSE')\n",
        "    sns.heatmap(rmse_pivot, annot=True, fmt='.2f', cmap='Reds', ax=ax1, cbar_kws={'label': 'RMSE (Â°C)'})\n",
        "    ax1.set_title('RMSE\\n(Lower is Better)', fontweight='bold')\n",
        "    \n",
        "    # 2. Correlation Heatmap\n",
        "    ax2 = axes[0, 1]\n",
        "    r_pivot = validation_results.pivot(index='Station', columns='Model', values='R')\n",
        "    sns.heatmap(r_pivot, annot=True, fmt='.3f', cmap='Blues', ax=ax2, cbar_kws={'label': 'Correlation (R)'})\n",
        "    ax2.set_title('Correlation\\n(Higher is Better)', fontweight='bold')\n",
        "    \n",
        "    # 3. NSE Heatmap\n",
        "    ax3 = axes[0, 2]\n",
        "    nse_pivot = validation_results.pivot(index='Station', columns='Model', values='NSE')\n",
        "    sns.heatmap(nse_pivot, annot=True, fmt='.3f', cmap='Greens', ax=ax3, cbar_kws={'label': 'NSE'})\n",
        "    ax3.set_title('Nash-Sutcliffe Efficiency\\n(Higher is Better)', fontweight='bold')\n",
        "    \n",
        "    # 4. PBIAS Heatmap\n",
        "    ax4 = axes[1, 0]\n",
        "    pbias_pivot = validation_results.pivot(index='Station', columns='Model', values='PBIAS')\n",
        "    sns.heatmap(pbias_pivot, annot=True, fmt='.1f', cmap='RdBu_r', center=0, ax=ax4, cbar_kws={'label': 'PBIAS (%)'})\n",
        "    ax4.set_title('Percent Bias\\n(Closer to 0 is Better)', fontweight='bold')\n",
        "    \n",
        "    # 5. Model Performance Box Plot\n",
        "    ax5 = axes[1, 1]\n",
        "    models = list(model_colors.keys())\n",
        "    rmse_data = [validation_results[validation_results['Model'] == model]['RMSE'].values for model in models]\n",
        "    bp = ax5.boxplot(rmse_data, labels=models, patch_artist=True)\n",
        "    for patch, model in zip(bp['boxes'], models):\n",
        "        patch.set_facecolor(model_colors[model])\n",
        "        patch.set_alpha(0.7)\n",
        "    ax5.set_title('RMSE Distribution\\nAcross All Stations', fontweight='bold')\n",
        "    ax5.set_ylabel('RMSE (Â°C)')\n",
        "    ax5.tick_params(axis='x', rotation=45)\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 6. Model Ranking\n",
        "    ax6 = axes[1, 2]\n",
        "    models_ranked = model_ranking.index\n",
        "    ranks = model_ranking['Average_Rank'].values\n",
        "    colors_list = [model_colors[model] for model in models_ranked]\n",
        "    bars = ax6.barh(range(len(models_ranked)), ranks, color=colors_list, alpha=0.7)\n",
        "    ax6.set_yticks(range(len(models_ranked)))\n",
        "    ax6.set_yticklabels(models_ranked)\n",
        "    ax6.set_xlabel('Average Rank')\n",
        "    ax6.set_title('Model Performance Ranking\\n(Lower is Better)', fontweight='bold')\n",
        "    ax6.grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # Add rank values on bars\n",
        "    for i, (bar, rank) in enumerate(zip(bars, ranks)):\n",
        "        ax6.text(rank + 0.05, bar.get_y() + bar.get_height()/2, \n",
        "                f'{rank:.2f}', ha='left', va='center', fontweight='bold')\n",
        "    \n",
        "    fig.suptitle('Part 4: Climate Model Validation Results\\nAMMAN ZARQA Basin, Jordan (1990-2014)', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.90)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"âœ… Validation visualization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_results"
      },
      "outputs": [],
      "source": [
        "# Display final workshop results\n",
        "print(\"ğŸ¯ WORKSHOP RESULTS SUMMARY\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if validation_results is not None and model_ranking is not None:\n",
        "    print(f\"âœ… Validation completed: {len(validation_results)} model-station combinations\")\n",
        "    print(f\"âœ… Models evaluated: {len(validation_results['Model'].unique())}\")\n",
        "    print(f\"âœ… Stations evaluated: {len(validation_results['Station'].unique())}\")\n",
        "    \n",
        "    print(f\"\\nğŸ† MODEL RANKING (Best to Worst):\")\n",
        "    for i, (model, row) in enumerate(model_ranking.iterrows(), 1):\n",
        "        rmse = row['RMSE']\n",
        "        r = row['R']\n",
        "        nse = row['NSE']\n",
        "        print(f\"  {i}. {model}: RMSE={rmse:.2f}Â°C, R={r:.3f}, NSE={nse:.3f}\")\n",
        "    \n",
        "    best_model = model_ranking.index[0]\n",
        "    worst_model = model_ranking.index[-1]\n",
        "    \n",
        "    print(f\"\\nğŸ“Š KEY FINDINGS:\")\n",
        "    print(f\"  ğŸ¥‡ Best performing model: {best_model}\")\n",
        "    print(f\"  ğŸ“‰ Worst performing model: {worst_model}\")\n",
        "    print(f\"  ğŸ“ RMSE range: {validation_results['RMSE'].min():.2f} - {validation_results['RMSE'].max():.2f}Â°C\")\n",
        "    print(f\"  ğŸ“ˆ Correlation range: {validation_results['R'].min():.3f} - {validation_results['R'].max():.3f}\")\n",
        "    \n",
        "    print(f\"\\nğŸ“‹ DETAILED VALIDATION RESULTS:\")\n",
        "    display(validation_results)\n",
        "    \n",
        "    print(f\"\\nğŸ† MODEL RANKING TABLE:\")\n",
        "    display(model_ranking)\n",
        "\n",
        "print(f\"\\nğŸ‰ WORKSHOP COMPLETE!\")\n",
        "print(f\"ğŸ“ You have successfully validated climate models for AMMAN ZARQA Basin!\")\n",
        "print(f\"ğŸ“š Skills gained: NetCDF processing, climatology calculation, statistical validation\")\n",
        "print(f\"ğŸ”— Repository: https://github.com/MoawiahHussien/climate-model-validation-workshop\")"
      ]
    }
  ]
}
